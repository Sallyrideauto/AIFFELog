{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSz4AJfAHRfN"
   },
   "source": [
    "# Going Deeper NLP Project 4. Vocabulary Size를 변경해서 뉴스 카테고리를 다중 분류하기\n",
    "\n",
    "## 📍 About Project\n",
    "- `Reuters` 뉴스 데이터셋을 이용하여 해당 뉴스가 어느 카테고리에 속하는지를 예측\n",
    "- \b단어의 수에 따라 모델의 성능이 어떻게 변화하는지 테스트\n",
    "- `num_words`로 사용할 단어의 수를 조정\n",
    "  - 빈도수가 많은 순서대로 나열했을 때, `num_words`의 인자로 준 정숫값만큼의 단어를 사용\n",
    "  - 나머지 단어는 전부 `<unk>`로 처리하는 원리\n",
    "  - 변화된 단어 수에 따른 모델의 성능을 최소 3가지 이상의 케이스로 실험\n",
    "  - 사용할 모델\n",
    "    - 나이브 베이즈 분류기\n",
    "    - CNB\n",
    "    - 로지스틱 회귀\n",
    "    - 서포트 벡터 머신\n",
    "    - 결정 트리\n",
    "    - 랜덤 포레스트 \n",
    "    - 그래디언트 부스팅 트리\n",
    "    - 보팅\n",
    "\n",
    "## 🎯 Rubric\n",
    "1. 분류 모델의 `accuracy`가 기준 이상 높게 나왔는가?<br>\n",
    "3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.<br>\n",
    "2. 분류 모델의 `F1 score`가 기준 이상 높게 나왔는가?<br>\n",
    "`Vocabulary size`에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.<br>\n",
    "3. 딥러닝 모델을 활용해 성능이 비교 및 확인되었는가?<br>\n",
    "동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qLVh_pILU3vq"
   },
   "outputs": [],
   "source": [
    "# 실습에 필요한 디렉터리 생성\n",
    "! mkdir -p ~/aiffel/reuters_classifiaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uqvIx8Hfvx94"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters   # 로이터 뉴스 데이터 로드\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYdE6fVwMCC6",
    "outputId": "60852cc7-598b-443c-bc15-3f61eab4d7ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 로드\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnCMR6hFVTSY"
   },
   "source": [
    "* `num_words`\n",
    "  * 데이터에서 빈도수 기준으로 상위 몇 번째 단어까지 사용할 것인지 조절\n",
    "  * 각 단어는 고유한 번호가 정해져 있는 상태이고, 이를 통해서 사용할 단어의 수를 결정\n",
    "  * 해당 데이터셋의 단어들은 등장 빈도의 수가 높은 순서대로 낮은 정수가 맵핑되어 있음\n",
    "  * 코드에서 `num_words=10000`은 1~10000번 단어만 사용함을 의미\n",
    "* 주의\n",
    "  * `num_words`의 인자로 10,000을 기재한다고 해서 10,000보다 높은 정수가 맵핑된 단어들이 받아온 데이터에서 사라지지 않음\n",
    "  * 주어진 값보다 큰 번호를 가졌던 단어들은 특정 번호로 전부 맵핑\n",
    "  * OOV 문제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09y2OwUcMHlu",
    "outputId": "9791e2fb-7d9a-48a7-b425-9c9faf9d251e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 출력\n",
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1IRsJtBMJoi",
    "outputId": "49cd1ecf-4c9d-409e-c2c9-6a493f783d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 숫자 시퀀스 출력\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPXQMESUWgqo"
   },
   "source": [
    "* 이미 뉴스 데이터를 다운로드할 때 단어가 아닌 해당 번호로 변환되어 출력됨\n",
    "* 대부분의 자연어 처리에서는 텍스트를 숫자로 수치화하는 과정 필요\n",
    "* Tensorflow 데이터셋에서는 이미 전처리가 진행된 데이터를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwx_BSJrMNES",
    "outputId": "52c54993-16d1-4d92-e04f-97fe4090d16d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# label 출력\n",
    "print(y_train[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAyaxJTmMUOc",
    "outputId": "cf8ba2b5-ccb9-4206-8170-ad3c87ea4975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스의 수 : 46\n"
     ]
    }
   ],
   "source": [
    "# 현재 클래스의 개수 확인\n",
    "# 숫자 0부터 시작되는 레이블로, 모든 레이블 중 최대값을 구하고 1을 더하는 방식\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8tRrT5m8MWrM",
    "outputId": "38211ae6-2319-4ea2-f793-4d758251263c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 뉴스 데이터의 분포 시각화\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "Dy1xrV0LMa64",
    "outputId": "c9fcc989-5206-40f8-b294-a2020467c830"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 클래스 분포 시각화\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9oQ2HR4XXwl"
   },
   "source": [
    "* 해당 뉴스 데이터는 3, 4번 클래스가 대부분을 차지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvVzXz-NMtTT",
    "outputId": "98fdeb86-6650-4c27-be24-6b1867f0ab1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스의 빈도 수 출력\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwZ1yzfEM1ZY",
    "outputId": "a68c3667-b816-42f6-9f43-488bb937172d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 원본(텍스트 형태) 뉴스 데이터로 변환\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "# 로이터 뉴스 데이터는 '단어'를 key값으로, 고유한 '정수'를 value로 가지는 dictionary를 제공\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hxLzigOYZIE",
    "outputId": "a9aa7bb6-6df8-461e-dff9-11c6ced6027d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index['the'] :  1\n",
      "word_index['it'] :  13\n",
      "word_index['they'] :  74\n",
      "word_index['i'] :  265\n",
      "word_index['you'] :  1025\n"
     ]
    }
   ],
   "source": [
    "print(\"word_index['the'] : \", word_index['the'])\n",
    "print(\"word_index['it'] : \", word_index['it'])\n",
    "print(\"word_index['they'] : \", word_index['they'])\n",
    "print(\"word_index['i'] : \", word_index['i'])\n",
    "print(\"word_index['you'] : \", word_index['you'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oO5WfT1XX8MS"
   },
   "source": [
    "* 현재의 정수 시퀀스 데이터를 텍스트 형태로 되돌려야 하므로, 정수로부터 단어를 얻을 수 있는 `index_word`가 필요\n",
    "* `word_index`에 입력했을 떄 얻는 숫자에서 3을 더한 숫자가 본래 고유한 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIHD8LpcNDNV",
    "outputId": "cf34b535-e3b5-444f-d5f3-a1b7b171b2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykRvA9SQNFMC",
    "outputId": "cee4bf0e-1873-45c4-82d4-c5c54cdfaff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_word[4] :  the\n",
      "index_to_word[16] :  it\n",
      "index_to_word[77] :  they\n",
      "index_to_word[268] :  i\n",
      "index_to_word[1028] :  you\n"
     ]
    }
   ],
   "source": [
    "print(\"index_to_word[4] : \", index_to_word[4])\n",
    "print(\"index_to_word[16] : \", index_to_word[16])\n",
    "print(\"index_to_word[77] : \", index_to_word[77])\n",
    "print(\"index_to_word[268] : \", index_to_word[268])\n",
    "print(\"index_to_word[1028] : \", index_to_word[1028])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dgNO0YEZnub"
   },
   "source": [
    "* 0번, 1번, 2번은 각각 `<pad>`, `<sos>`, `<unk>`라는 자연어 처리를 위한 특별한 토큰들을 위해 맵핑된 번호\n",
    "* 만들어진 `index_to_word`에 추가적으로 해당 작업을 해 주어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVnl7pU6NG3y",
    "outputId": "bf10213a-e03e-4c0b-dedb-58b249f5e1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrKJiDAVNJYl",
    "outputId": "a4335542-513e-41af-ca9e-5fc6066b1320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# index_to_word를 통해서 첫 번째 훈련용 뉴스 기사를 원래 텍스트로 복원\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u73S9e3idq4k"
   },
   "source": [
    "* OOV(Out-Of-Vocabulary) 문제\n",
    "  * 기계가 미처 배우지 못한 모르는 단어\n",
    "  * 어떤 단어를 기계가 모르는 단어로 판단하면, 기계는 해당 단어를 전부 `<unk>`라는 일관된 특별 토큰으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHZFT3VoNOtt",
    "outputId": "0551a3bc-2b47-4a6b-b368-0c508a7270de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the transaction is expected to be completed\n"
     ]
    }
   ],
   "source": [
    "# index_word를 사용하여 [4, 587, 23, 133, 6, 30, 515]인 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "print(' '.join([index_to_word[index] for index in [4, 587, 23, 133, 6, 30, 515]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR-eZfucNaH_",
    "outputId": "fcef3896-6851-4383-9d0e-6b04c61ddea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the staffing is expected to be completed\n"
     ]
    }
   ],
   "source": [
    "# [4, 12000, 23, 133, 6, 30, 515]인 정수 시퀀스의 문장 출력\n",
    "print(' '.join([index_to_word[index] for index in [4, 12000, 23, 133, 6, 30, 515]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rx0tbh4DeuiM"
   },
   "source": [
    "* 해당 정수 시퀀스는 `[4, 2, 23, 133, 6, 30, 515]`\n",
    "* 12,000은 10,000을 넘는 숫자로 OOV에 해당되므로 `<unk>`인 2로 변환되어 데이터가 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpqEE9LINi_l",
    "outputId": "86c5b0c7-e9ec-4b6e-9307-fc0c720fef71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CnyWeqYNr11",
    "outputId": "b11d6dcd-b1c3-4aac-a337-aed3bd0c562a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPyg0dWrNuEg",
    "outputId": "6f5d956b-12ac-449a-c609-a8dc96cb0e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3', '<sos> generale de banque sa lt <unk> br and lt heller overseas corp of chicago have each taken 50 pct stakes in <unk> company sa <unk> factors generale de banque said in a statement it gave no financial details of the transaction sa <unk> <unk> turnover in 1986 was 17 5 billion belgian francs reuter 3', '<sos> shr 3 28 dlrs vs 22 cts shr diluted 2 99 dlrs vs 22 cts net 46 0 mln vs 3 328 000 avg shrs 14 0 mln vs 15 2 mln year shr 5 41 dlrs vs 1 56 dlrs shr diluted 4 94 dlrs vs 1 50 dlrs net 78 2 mln vs 25 9 mln avg shrs 14 5 mln vs 15 1 mln note earnings per share reflect the two for one split effective january 6 1987 per share amounts are calculated after preferred stock dividends loss continuing operations for the qtr 1986 includes gains of sale of investments in <unk> corp of 14 mln dlrs and associated companies of 4 189 000 less writedowns of investments in national <unk> inc of 11 8 mln and <unk> corp of 15 6 mln reuter 3', \"<sos> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <unk> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <unk> financial eligibility standards indicated as many as one half of <unk> borrowers who received new loans from the agency in 1986 would be <unk> under the proposed system the agency has proposed evaluating <unk> credit using a variety of financial ratios instead of relying solely on <unk> ability senate agriculture committee chairman patrick leahy d vt <unk> the proposed eligibility changes telling <unk> administrator <unk> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <unk> its 70 billion dlr loan portfolio in a <unk> yet <unk> manner crowley of gao <unk> <unk> arm said the proposed credit <unk> system attempted to ensure that <unk> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\", '<sos> seton co said its board has received a proposal from chairman and chief executive officer philip d <unk> to acquire seton for 15 75 dlrs per share in cash seton said the acquisition bid is subject to <unk> arranging the necessary financing it said he intends to ask other members of senior management to participate the company said <unk> owns 30 pct of seton stock and other management members another 7 5 pct seton said it has formed an independent board committee to consider the offer and has deferred the annual meeting it had scheduled for march 31 reuter 3']\n",
      "['<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3', \"<sos> philippine sugar production in the 1987 88 crop year ending august has been set at 1 6 mln tonnes up from a provisional 1 3 mln tonnes this year sugar regulatory administration <unk> chairman <unk> yulo said yulo told reuters a survey during the current milling season which ends next month showed the 1986 87 estimate would almost certainly be met he said at least 1 2 mln tonnes of the 1987 88 crop would be earmarked for domestic consumption yulo said about 130 000 tonnes would be set aside for the u s sugar quota 150 000 tonnes for strategic reserves and 50 000 tonnes would be sold on the world market he said if the government approved a long standing <unk> recommendation to manufacture ethanol the project would take up another 150 000 tonnes slightly raising the target the government for its own reasons has been delaying approval of the project but we expect it to come through by july yulo said ethanol could make up five pct of gasoline cutting the oil import bill by about 300 mln pesos yulo said three major philippine <unk> were ready to start manufacturing ethanol if the project was approved the ethanol project would result in employment for about 100 000 people sharply reducing those thrown out of work by depressed world sugar prices and a <unk> domestic industry production quotas set for the first time in 1987 88 had been submitted to president corazon aquino i think the president would rather wait <unk> the new congress <unk> after the may elections he said but there is really no need for such quotas we are right now producing just slightly over our own consumption level the producers have never enjoyed such high prices yulo said adding sugar was currently selling locally for 320 pesos per <unk> up from 190 pesos last august yulo said prices were driven up because of speculation following the <unk> bid to control production we are no longer concerned so much with the world market he said adding producers in the <unk> region had learned from their <unk> and diversified into corn and <unk> farming and <unk> production he said diversification into products other than ethanol was also possible within the sugar industry the <unk> long ago <unk> their <unk> yulo said they have 300 sugar mills compared with our 41 but they <unk> many of them and diversified production we want to call this a <unk> <unk> instead of the sugar industry he said sugarcane could be fed to pigs and livestock used for <unk> <unk> or used in room <unk> when you cut sugarcane you don't even have to produce sugar he said yulo said the philippines was lobbying for a renewal of the international sugar agreement which expired in 1984 as a major sugar producer we are urging them to write a new agreement which would revive world prices yulo said if there is no agreement world prices will always be depressed particularly because the european community is <unk> its producers and dumping sugar on the markets he said current world prices holding steady at about 7 60 cents per pound were <unk> for the philippines where production costs ranged from 12 to 14 cents a pound if the price holds steady for a while at 7 60 cents i expect the level to rise to about 11 cents a pound by the end of this year he said yulo said economists forecast a bullish sugar market by 1990 with world consumption <unk> production he said sugar markets were holding up despite <unk> from artificial sweeteners and high fructose corn syrup but we are not happy with the reagan administration he said since <unk> we have been regular suppliers of sugar to the u s in 1982 when they restored the quota system they cut <unk> in half without any justification manila was <unk> watching washington's moves to cut domestic support prices to 12 cents a pound from 18 cents the u s agriculture department last december slashed its 12 month 1987 sugar import quota from the philippines to 143 780 short tons from 231 660 short tons in 1986 yulo said despite next year's increased production target some philippine mills were expected to shut down at least four of the 41 mills were not working during the 1986 87 season he said we expect two or three more to follow suit during the next season reuter 3\", \"<sos> the agriculture department's widening of louisiana gulf differentials will affect county posted prices for number two yellow corn in ten states a usda official said all counties in iowa will be affected as will counties which use the gulf to price corn in illinois indiana tennessee kentucky missouri mississippi arkansas alabama and louisiana said <unk> <unk> deputy director of commodity operations division for the usda usda last night notified the grain industry that effective immediately all gulf differentials used to price interior corn would be widened on a sliding scale basis of four to eight cts depending on what the differential is usda's action was taken to lower excessively high posted county prices for corn caused by high gulf prices we've been following this louisiana gulf situation for a month and we don't think it's going to get back in line in any nearby time <unk> said <unk> said usda will probably narrow back the gulf differentials when and if gulf prices <unk> if we're off the mark now because we're too high wouldn't we be as much off the mark if we're too low he said while forecasting more adjustments if gulf prices fall <unk> said no other changes in usda's price system are being planned right now we don't tinker we don't make changes <unk> and we don't make changes often he said reuter 3\", '<sos> <unk> <unk> oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north <unk> fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to <unk> principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <unk> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3', '<sos> strong south <unk> winds were keeping many vessels trapped in the ice off the finnish and swedish coasts in one of the worst icy periods in the baltic for many years the finnish board of navigation said in finland and sweden up to 50 vessels were reported to be stuck in the ice and even the largest of the <unk> <unk> were having difficulties in breaking through to the <unk> ships <unk> officials said however icy conditions in the southern baltic at the soviet oil ports of <unk> and <unk> had eased they said weather officials in neighbouring sweden said the icy conditions in the baltic were the worst for 30 years with ships fighting a losing battle to keep moving in the coastal stretches of the gulf of <unk> which <unk> finland and sweden the ice is up to one <unk> thick with <unk> and <unk> packing it into almost <unk> walls three metres high swedish <unk> officials said weather forecasts say winds may ease during the weekend but a further drop in temperature could bring shipping to a standstill the officials said reuter 3']\n"
     ]
    }
   ],
   "source": [
    "# 각각 5개씩 출력 해 보고, 제대로 변환이 되었는지 확인\n",
    "print(x_train[:5])\n",
    "print(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npfTV8zAOAFD",
    "outputId": "d6ecc467-1f7f-4c83-92de-688a295e51ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런의 CountVectorizer를 이용하여 DTM 생성 후 DTM의 크기 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7vF5OjW3OPB8",
    "outputId": "5dd70458-c870-41b3-9258-e00a25be1172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "# TfidfTransformer를 이용하여 TF-IDF 행렬 생성\n",
    "# TF-IDF Matrix는 추가적인 전처리를 하지 않는 이상, DTM과 동일한 크기를 가짐\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KvDD6RBzkX6B"
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzeS_of-K5Hb"
   },
   "source": [
    "* 나이브 베이즈 분류기\n",
    "* CNB(Complement Naive Bayes)\n",
    "* 로지스틱 회귀(Logistic Regression)\n",
    "* 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "* 결정 트리(Decision Tree)\n",
    "* 랜덤 포레스트(Random Forest)\n",
    "* 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "* 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZEIqNNMGgy88"
   },
   "outputs": [],
   "source": [
    "def train_ml(tfidfv, y_train, tfidfv_test, y_test):\n",
    "    # 나이브 베이즈 분류기 \n",
    "    mod = MultinomialNB()\n",
    "    mod.fit(tfidfv, y_train)\n",
    "    # fit() 함수를 이용하여 훈련 데이터와 해당 훈련 데이터에 대한 레이블을 인자로 사용하여 모델이 이를 학습하도록 함\u001f\n",
    "    \n",
    "    # 테스트 데이터에 대한 정확도를 측정하기 위해 훈련 데이터와 동일한 전처리 수행 필요 - TF-IDF 변환\n",
    "    mod_predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"나이브 베이즈 정확도:\", accuracy_score(y_test, mod_predicted)) #예측값과 실제값 비교를 통한 정확도 측정\n",
    "    # 정밀도, 재현율, F1 Score 측정\n",
    "    print(classification_report(y_test, mod.predict(tfidfv_test), zero_division=0))\n",
    "\n",
    "    # CNB(Complement Naive Bayes)\n",
    "    cb = ComplementNB()\n",
    "    cb.fit(tfidfv, y_train)\n",
    "    \n",
    "    cb_predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"CNB 정확도:\", accuracy_score(y_test, cb_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, cb.predict(tfidfv_test), zero_division=0))\n",
    "    \n",
    "    # 로지스틱 회귀 \n",
    "    lr = LogisticRegression(C=10000, penalty='l2')\n",
    "    lr.fit(tfidfv, y_train)\n",
    "\n",
    "    lr_predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, lr_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, lr.predict(tfidfv_test), zero_division=0))\n",
    "    \n",
    "    # 선형 서포트 벡터 머신 \n",
    "    lsvc = LinearSVC(C=10000, penalty='l1', max_iter=500, dual=False)\n",
    "    lsvc.fit(tfidfv, y_train)\n",
    "    \n",
    "    lsvc_predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"SVM 정확도:\", accuracy_score(y_test, lsvc_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, lsvc.predict(tfidfv_test), zero_division=0))\n",
    "\n",
    "    # 결정 트리(Decision Tree) \n",
    "    tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "    tree.fit(tfidfv, y_train)\n",
    "    \n",
    "    tree_predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"결정 트리 정확도:\", accuracy_score(y_test, tree_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, tree.predict(tfidfv_test), zero_division=0))\n",
    "\n",
    "    # 랜덤 포레스트(Random Forest)\n",
    "    forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "    forest.fit(tfidfv, y_train)\n",
    "    \n",
    "    forest_predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"랜덤 포레스트 정확도:\", accuracy_score(y_test, forest_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, forest.predict(tfidfv_test), zero_division=0))\n",
    "    \n",
    "    # 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "    grbt = GradientBoostingClassifier(random_state=0, verbose=3) # verbose=3\n",
    "    grbt.fit(tfidfv, y_train)\n",
    "\n",
    "    grbt_predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"그래디언트 부스팅 트리 정확도:\", accuracy_score(y_test, grbt_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, grbt.predict(tfidfv_test), zero_division=0))\n",
    "\n",
    "    # 보팅(Voting)\n",
    "    voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "        ], voting='soft', n_jobs=-1)\n",
    "    voting_classifier.fit(tfidfv, y_train)\n",
    "    \n",
    "    voting_classifier_predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "    print(\"보팅 정확도:\", accuracy_score(y_test, voting_classifier_predicted)) #예측값과 실제값 비교\n",
    "    print(classification_report(y_test, voting_classifier.predict(tfidfv_test), zero_division=0))\n",
    "\n",
    "    return mod, cb, lr, lsvc, tree, forest, grbt, voting_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12YVJByYiO6_",
    "outputId": "648eceed-4dc9-494b-bf98-5a198c1b27e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6567230632235085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.62      0.69      0.65       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.81      0.90      0.85       813\n",
      "           4       0.51      0.96      0.67       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.08      0.15        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.66      0.63      0.64        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       1.00      0.03      0.05        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.69      0.56      0.61        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.60      0.78      0.68       133\n",
      "          20       1.00      0.04      0.08        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       1.00      0.03      0.06        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.66      2246\n",
      "   macro avg       0.17      0.10      0.10      2246\n",
      "weighted avg       0.59      0.66      0.58      2246\n",
      "\n",
      "CNB 정확도: 0.7707034728406055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.64      0.88      0.74       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.91      0.89      0.90       813\n",
      "           4       0.75      0.92      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.50      0.13      0.21        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.55      0.73      0.63        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.58      0.59      0.59        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.11      0.18         9\n",
      "          16       0.67      0.79      0.73        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.55      0.60      0.57        20\n",
      "          19       0.55      0.80      0.65       133\n",
      "          20       0.75      0.30      0.43        70\n",
      "          21       0.74      0.63      0.68        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.75      0.50      0.60        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.85      0.74      0.79        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.25      0.10      0.14        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.31      0.47        13\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       1.00      0.20      0.33         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.75      0.77      0.75      2246\n",
      "\n",
      "로지스틱 회귀 정확도: 0.8076580587711487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.75      0.78      0.76       105\n",
      "           2       0.74      0.85      0.79        20\n",
      "           3       0.92      0.93      0.93       813\n",
      "           4       0.81      0.87      0.84       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.71      0.69        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.64      0.73      0.68        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.59      0.59      0.59        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.67      0.44      0.53         9\n",
      "          16       0.68      0.75      0.71        99\n",
      "          17       0.75      0.75      0.75        12\n",
      "          18       0.86      0.60      0.71        20\n",
      "          19       0.68      0.68      0.68       133\n",
      "          20       0.62      0.49      0.54        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.64      0.58      0.61        12\n",
      "          24       0.62      0.53      0.57        19\n",
      "          25       0.95      0.68      0.79        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.57      0.40      0.47        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       0.88      0.58      0.70        12\n",
      "          31       0.78      0.54      0.64        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.36      0.36      0.36        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.75      0.30      0.43        10\n",
      "          41       0.83      0.62      0.71         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.75      1.00      0.86         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.71      0.62      0.64      2246\n",
      "weighted avg       0.80      0.81      0.80      2246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.7123775601068566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.50      0.63        12\n",
      "           1       0.58      0.60      0.59       105\n",
      "           2       0.70      0.35      0.47        20\n",
      "           3       0.89      0.89      0.89       813\n",
      "           4       0.80      0.82      0.81       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.79      0.79      0.79        14\n",
      "           7       0.33      0.33      0.33         3\n",
      "           8       0.42      0.55      0.48        38\n",
      "           9       0.61      0.68      0.64        25\n",
      "          10       0.56      0.73      0.64        30\n",
      "          11       0.56      0.66      0.61        83\n",
      "          12       0.18      0.23      0.20        13\n",
      "          13       0.44      0.43      0.44        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.22      0.31         9\n",
      "          16       0.50      0.61      0.55        99\n",
      "          17       0.33      0.25      0.29        12\n",
      "          18       0.71      0.50      0.59        20\n",
      "          19       0.56      0.56      0.56       133\n",
      "          20       0.48      0.36      0.41        70\n",
      "          21       0.54      0.56      0.55        27\n",
      "          22       0.25      0.14      0.18         7\n",
      "          23       0.45      0.42      0.43        12\n",
      "          24       0.37      0.37      0.37        19\n",
      "          25       0.81      0.55      0.65        31\n",
      "          26       0.27      0.38      0.32         8\n",
      "          27       0.25      0.25      0.25         4\n",
      "          28       0.25      0.20      0.22        10\n",
      "          29       0.12      0.25      0.17         4\n",
      "          30       0.22      0.17      0.19        12\n",
      "          31       0.50      0.15      0.24        13\n",
      "          32       0.67      0.60      0.63        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.33      0.29      0.31         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.44      0.36      0.40        11\n",
      "          37       0.25      0.50      0.33         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.33      0.20      0.25        10\n",
      "          41       0.38      0.38      0.38         8\n",
      "          42       0.67      0.67      0.67         3\n",
      "          43       0.67      0.67      0.67         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.71      2246\n",
      "   macro avg       0.50      0.44      0.45      2246\n",
      "weighted avg       0.71      0.71      0.71      2246\n",
      "\n",
      "결정 트리 정확도: 0.6202137132680321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.72      0.42      0.53       105\n",
      "           2       0.62      0.50      0.56        20\n",
      "           3       0.93      0.83      0.88       813\n",
      "           4       0.40      0.90      0.56       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.90      0.64      0.75        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.88      0.88      0.88        25\n",
      "          10       0.85      0.77      0.81        30\n",
      "          11       0.64      0.51      0.56        83\n",
      "          12       0.14      0.08      0.10        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.59      0.84      0.69        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.62      0.29      0.39       133\n",
      "          20       0.27      0.06      0.09        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       0.86      0.19      0.32        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.18      0.18      2246\n",
      "weighted avg       0.61      0.62      0.58      2246\n",
      "\n",
      "랜덤 포레스트 정확도: 0.674087266251113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.33      0.27        12\n",
      "           1       0.45      0.77      0.57       105\n",
      "           2       0.30      0.30      0.30        20\n",
      "           3       0.82      0.90      0.86       813\n",
      "           4       0.61      0.83      0.70       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.67      0.43      0.52        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.67      0.53      0.59        38\n",
      "           9       0.70      0.28      0.40        25\n",
      "          10       0.75      0.30      0.43        30\n",
      "          11       0.55      0.59      0.57        83\n",
      "          12       0.40      0.15      0.22        13\n",
      "          13       0.37      0.19      0.25        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.59      0.59      0.59        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.50      0.25      0.33        20\n",
      "          19       0.69      0.54      0.61       133\n",
      "          20       0.57      0.29      0.38        70\n",
      "          21       0.67      0.30      0.41        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       1.00      0.32      0.49        31\n",
      "          26       1.00      0.25      0.40         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.50      0.08      0.14        12\n",
      "          31       0.67      0.15      0.25        13\n",
      "          32       0.67      0.20      0.31        10\n",
      "          33       1.00      0.60      0.75         5\n",
      "          34       0.50      0.14      0.22         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.33      0.09      0.14        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.67      0.33      0.44         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.46      0.27      0.31      2246\n",
      "weighted avg       0.66      0.67      0.64      2246\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.4608           11.00m\n",
      "         2       95544.1548           11.16m\n",
      "         3      105411.1055           11.28m\n",
      "         4 26490374809120059619893320924222374741943986946048.0000           11.47m\n",
      "         5 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           11.74m\n",
      "         6 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           11.48m\n",
      "         7 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           11.26m\n",
      "         8 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           11.09m\n",
      "         9 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           10.93m\n",
      "        10 3332464259228453694671945105465820387521328203545526380221295913764842145866429631276902168311601749602693928777633481065758720.0000           10.78m\n",
      "        11 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.63m\n",
      "        12 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.49m\n",
      "        13 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.34m\n",
      "        14 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.27m\n",
      "        15 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.14m\n",
      "        16 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           10.02m\n",
      "        17 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.87m\n",
      "        18 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.72m\n",
      "        19 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.59m\n",
      "        20 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.48m\n",
      "        21 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.34m\n",
      "        22 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.21m\n",
      "        23 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            9.08m\n",
      "        24 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.97m\n",
      "        25 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.90m\n",
      "        26 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.78m\n",
      "        27 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.66m\n",
      "        28 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.52m\n",
      "        29 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.42m\n",
      "        30 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.30m\n",
      "        31 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.19m\n",
      "        32 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            8.09m\n",
      "        33 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.97m\n",
      "        34 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.86m\n",
      "        35 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.72m\n",
      "        36 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.60m\n",
      "        37 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.48m\n",
      "        38 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.35m\n",
      "        39 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.23m\n",
      "        40 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.10m\n",
      "        41 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.97m\n",
      "        42 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.87m\n",
      "        43 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.75m\n",
      "        44 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.64m\n",
      "        45 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.52m\n",
      "        46 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.40m\n",
      "        47 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.28m\n",
      "        48 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.17m\n",
      "        49 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            6.05m\n",
      "        50 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.93m\n",
      "        51 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.81m\n",
      "        52 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.70m\n",
      "        53 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.58m\n",
      "        54 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.46m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        55 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.34m\n",
      "        56 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.22m\n",
      "        57 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            5.11m\n",
      "        58 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.99m\n",
      "        59 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.87m\n",
      "        60 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.75m\n",
      "        61 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.63m\n",
      "        62 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.51m\n",
      "        63 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.40m\n",
      "        64 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.28m\n",
      "        65 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.16m\n",
      "        66 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            4.04m\n",
      "        67 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.92m\n",
      "        68 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.80m\n",
      "        69 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.68m\n",
      "        70 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.57m\n",
      "        71 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.45m\n",
      "        72 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.33m\n",
      "        73 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.21m\n",
      "        74 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            3.09m\n",
      "        75 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.97m\n",
      "        76 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.85m\n",
      "        77 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.73m\n",
      "        78 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.61m\n",
      "        79 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.50m\n",
      "        80 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.38m\n",
      "        81 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.26m\n",
      "        82 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.14m\n",
      "        83 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            2.02m\n",
      "        84 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.90m\n",
      "        85 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.78m\n",
      "        86 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.66m\n",
      "        87 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.55m\n",
      "        88 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.43m\n",
      "        89 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.31m\n",
      "        90 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.19m\n",
      "        91 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            1.07m\n",
      "        92 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           57.11s\n",
      "        93 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           49.98s\n",
      "        94 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           42.84s\n",
      "        95 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           35.70s\n",
      "        96 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           28.56s\n",
      "        97 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           21.42s\n",
      "        98 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000           14.28s\n",
      "        99 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            7.14s\n",
      "       100 14834291270935598097793813192422686817633454293445808551806972586635235618984506254543094943361504759490214512223227966451089408.0000            0.00s\n",
      "그래디언트 부스팅 트리 정확도: 0.7666963490650045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        12\n",
      "           1       0.77      0.68      0.72       105\n",
      "           2       0.78      0.70      0.74        20\n",
      "           3       0.88      0.91      0.89       813\n",
      "           4       0.76      0.83      0.79       474\n",
      "           5       0.50      0.20      0.29         5\n",
      "           6       0.80      0.86      0.83        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.64      0.66      0.65        38\n",
      "           9       0.74      0.80      0.77        25\n",
      "          10       0.90      0.87      0.88        30\n",
      "          11       0.62      0.64      0.63        83\n",
      "          12       0.33      0.46      0.39        13\n",
      "          13       0.62      0.49      0.55        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.38      0.33      0.35         9\n",
      "          16       0.73      0.73      0.73        99\n",
      "          17       0.27      0.25      0.26        12\n",
      "          18       0.59      0.50      0.54        20\n",
      "          19       0.68      0.65      0.67       133\n",
      "          20       0.67      0.46      0.54        70\n",
      "          21       0.69      0.74      0.71        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.54      0.58      0.56        12\n",
      "          24       0.61      0.58      0.59        19\n",
      "          25       0.89      0.55      0.68        31\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.50      0.50      0.50         4\n",
      "          28       0.38      0.30      0.33        10\n",
      "          29       0.23      0.75      0.35         4\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.62      0.38      0.48        13\n",
      "          32       1.00      0.90      0.95        10\n",
      "          33       0.75      0.60      0.67         5\n",
      "          34       0.67      0.29      0.40         7\n",
      "          35       0.80      0.67      0.73         6\n",
      "          36       0.62      0.45      0.53        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.33      0.33      0.33         3\n",
      "          39       0.40      0.40      0.40         5\n",
      "          40       0.40      0.20      0.27        10\n",
      "          41       0.56      0.62      0.59         8\n",
      "          42       0.67      0.67      0.67         3\n",
      "          43       0.67      0.67      0.67         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.58      0.58      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyride/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 정확도: 0.8116651825467498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.77      0.74      0.76       105\n",
      "           2       0.73      0.80      0.76        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.83      0.88      0.85       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.86      0.86      0.86        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.70      0.68      0.69        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.90      0.92        30\n",
      "          11       0.65      0.69      0.67        83\n",
      "          12       0.46      0.46      0.46        13\n",
      "          13       0.68      0.62      0.65        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.57      0.44      0.50         9\n",
      "          16       0.72      0.75      0.73        99\n",
      "          17       0.53      0.67      0.59        12\n",
      "          18       0.79      0.55      0.65        20\n",
      "          19       0.68      0.69      0.68       133\n",
      "          20       0.62      0.49      0.54        70\n",
      "          21       0.65      0.81      0.72        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.60      0.75      0.67        12\n",
      "          24       0.67      0.63      0.65        19\n",
      "          25       0.95      0.68      0.79        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.44      0.40      0.42        10\n",
      "          29       0.40      1.00      0.57         4\n",
      "          30       0.67      0.50      0.57        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      1.00      1.00        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.67      0.80         6\n",
      "          36       0.56      0.45      0.50        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.40      0.44         5\n",
      "          40       0.67      0.20      0.31        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.71      0.66      0.66      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n",
      "run time : 0:24:19\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start = time.time() \n",
    "\n",
    "mod, cb, lr, lsvc, tree, forest, grbt, voting_classifier = train_ml(tfidfv, y_train, tfidfv_test, y_test)\n",
    "\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print('run time :', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Wd2saCyDSpZm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> <unk> <unk> oil and gas partnership said it completed the sale of interests in two major oil and gas fields to lt energy assets international corp for 21 mln dlrs the company said it sold about one half of its 50 pct interest in the oak hill and north <unk> fields its two largest producing properties it said it used about 20 mln dlrs of the proceeds to <unk> principal on its senior secured notes semi annual principal payments on the remaining 40 mln dlrs of notes have been satisfied until december 1988 as a result it said the company said the note agreements were amended to reflect an easing of some financial covenants and an increase of interest to 13 5 pct from 13 0 pct until december 1990 it said the <unk> exercise price for 1 125 000 warrants was also reduced to 50 cts from 1 50 dlrs the company said energy assets agreed to share the costs of increasing production at the oak hill field reuter 3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[3] # 네 번째 샘플의 원문 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ntJB8uoSZTAZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[3] # 해당 샘플의 레이블 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "B3Rd98ADZctZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델이 결정한 확률을 그래프로 시각화\n",
    "probability = mod.predict_proba(tfidfv_test[3])[0]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (11,5)\n",
    "plt.bar(mod.classes_, probability)\n",
    "plt.xlim(-1, 21)\n",
    "plt.xticks(mod.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aCa6eLcZZsl3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.predict(tfidfv_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7NMSks1dZ0DA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 혼동 행렬(confusion matrix) 시각화\n",
    "def graph_confusion_matrix(mod, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, mod.predict(x_test)))\n",
    "  #, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "graph_confusion_matrix(mod, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqAse4CWLYM2"
   },
   "source": [
    "## Vocabulary Size를 변경해서 시도 해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cLQnhth0iQaz"
   },
   "outputs": [],
   "source": [
    "(x_train_n, y_train_n), (x_test_n, y_test_n) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "(x_train_5k, y_train_5k), (x_test_5k, y_test_5k) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "(x_train_15k, y_train_15k), (x_test_15k, y_test_15k) = reuters.load_data(num_words=15000, test_split=0.2)\n",
    "(x_train_20k, y_train_20k), (x_test_20k, y_test_20k) = reuters.load_data(num_words=20000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "S8ZWFppxRKig"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 훈련 샘플의 수: 8982\n",
      "모든 단어 사용 시 테스트 샘플의 수: 2246\n",
      "5000 단어 사용 시 훈련 샘플의 수: 8982\n",
      "5000 단어 사용 시 테스트 샘플의 수: 2246\n",
      "15000 단어 사용 시 훈련 샘플의 수: 8982\n",
      "15000 단어 사용 시 테스트 샘플의 수: 2246\n",
      "20000 단어 사용 시 훈련 샘플의 수: 8982\n",
      "20000 단어 사용 시 테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('모든 단어 사용 시 훈련 샘플의 수: {}'.format(len(x_train_n)))\n",
    "print('모든 단어 사용 시 테스트 샘플의 수: {}'.format(len(x_test_n)))\n",
    "print('5000 단어 사용 시 훈련 샘플의 수: {}'.format(len(x_train_5k)))\n",
    "print('5000 단어 사용 시 테스트 샘플의 수: {}'.format(len(x_test_5k)))\n",
    "print('15000 단어 사용 시 훈련 샘플의 수: {}'.format(len(x_train_15k)))\n",
    "print('15000 단어 사용 시 테스트 샘플의 수: {}'.format(len(x_test_15k)))\n",
    "print('20000 단어 사용 시 훈련 샘플의 수: {}'.format(len(x_train_20k)))\n",
    "print('20000 단어 사용 시 테스트 샘플의 수: {}'.format(len(x_test_20k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EBaSnhvoaosd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 데이터의 숫자 시퀀스와 라벨\n",
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 23406, 28185, 5, 192, 510, 17, 12]\n",
      "3\n",
      "3\n",
      "----------------------------------\n",
      "5000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "3\n",
      "3\n",
      "----------------------------------\n",
      "15000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "3\n",
      "3\n",
      "----------------------------------\n",
      "15000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 데이터의 숫자 시퀀스와 라벨\")\n",
    "print(x_train_n[0])\n",
    "print(x_test_n[0])\n",
    "print(y_train_n[0])\n",
    "print(y_test_n[0])\n",
    "print(\"----------------------------------\")\n",
    "print(\"5000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\")\n",
    "print(x_train_5k[0])\n",
    "print(x_test_5k[0])\n",
    "print(y_train_5k[0])\n",
    "print(y_test_5k[0])\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\")\n",
    "print(x_train_15k[0])\n",
    "print(x_test_15k[0])\n",
    "print(y_train_15k[0])\n",
    "print(y_test_15k[0])\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 데이터의 숫자 시퀀스와 라벨\")\n",
    "print(x_train_20k[0])\n",
    "print(x_test_20k[0])\n",
    "print(y_train_20k[0])\n",
    "print(y_test_20k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "GO6Whff2a1mD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 클래스의 수 : 46\n",
      "5000 단어 사용 시 클래스의 수 : 46\n",
      "15000 단어 사용 시 클래스의 수 : 46\n",
      "20000 단어 사용 시 클래스의 수 : 46\n"
     ]
    }
   ],
   "source": [
    "num_classes_n = max(y_train_n) + 1\n",
    "print('모든 단어 사용 시 클래스의 수 : {}'.format(num_classes_n))\n",
    "num_classes_5k = max(y_train_5k) + 1\n",
    "print('5000 단어 사용 시 클래스의 수 : {}'.format(num_classes_5k))\n",
    "num_classes_15k = max(y_train_15k) + 1\n",
    "print('15000 단어 사용 시 클래스의 수 : {}'.format(num_classes_15k))\n",
    "num_classes_20k = max(y_train_20k) + 1\n",
    "print('20000 단어 사용 시 클래스의 수 : {}'.format(num_classes_20k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dz5SaLB2bG74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 훈련용 뉴스의 최대 길이 :2376\n",
      "모든 단어 사용 시 훈련용 뉴스의 평균 길이 :145.5398574927633\n",
      "----------------------------------\n",
      "5000 단어 사용 시 훈련용 뉴스의 최대 길이 :2376\n",
      "5000 단어 사용 시 훈련용 뉴스의 평균 길이 :145.5398574927633\n",
      "----------------------------------\n",
      "15000 단어 사용 시 훈련용 뉴스의 최대 길이 :2376\n",
      "15000 단어 사용 시 훈련용 뉴스의 평균 길이 :145.5398574927633\n",
      "----------------------------------\n",
      "20000 단어 사용 시 훈련용 뉴스의 최대 길이 :2376\n",
      "20000 단어 사용 시 훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('모든 단어 사용 시 훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train_n)))\n",
    "print('모든 단어 사용 시 훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train_n))/len(x_train_n)))\n",
    "print(\"----------------------------------\")\n",
    "print('5000 단어 사용 시 훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train_5k)))\n",
    "print('5000 단어 사용 시 훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train_5k))/len(x_train_5k)))\n",
    "print(\"----------------------------------\")\n",
    "print('15000 단어 사용 시 훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train_15k)))\n",
    "print('15000 단어 사용 시 훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train_15k))/len(x_train_15k)))\n",
    "print(\"----------------------------------\")\n",
    "print('20000 단어 사용 시 훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train_20k)))\n",
    "print('20000 단어 사용 시 훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train_20k))/len(x_train_20k)))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('all words')\n",
    "plt.hist([len(s) for s in x_train_n], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('5000 words')\n",
    "plt.hist([len(s) for s in x_train_5k], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('15000 words')\n",
    "plt.hist([len(s) for s in x_train_15k], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('20000 words')\n",
    "plt.hist([len(s) for s in x_train_20k], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8XeP1clTbTCw"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.countplot(x = y_train_n)\n",
    "plt.title('all words')\n",
    "plt.subplot(2,2,2)\n",
    "sns.countplot(x = y_train_5k)\n",
    "plt.title('5000 words')\n",
    "plt.subplot(2,2,3)\n",
    "sns.countplot(x = y_train_15k)\n",
    "plt.title('15000 words')\n",
    "plt.subplot(2,2,4)\n",
    "sns.countplot(x = y_train_20k)\n",
    "plt.title('20000 words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_VTANKUvbfOU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "5000 단어 사용 시 각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "15000 단어 사용 시 각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "20000 단어 사용 시 각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n"
     ]
    }
   ],
   "source": [
    "unique_elements_n, counts_elements_n = np.unique(y_train_n, return_counts = True)\n",
    "print(\"모든 단어 사용 시 각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements_n, counts_elements_n)))\n",
    "unique_elements_5k, counts_elements_5k = np.unique(y_train_5k, return_counts = True)\n",
    "print(\"5000 단어 사용 시 각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements_5k, counts_elements_5k)))\n",
    "unique_elements_15k, counts_elements_15k = np.unique(y_train_15k, return_counts = True)\n",
    "print(\"15000 단어 사용 시 각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements_15k, counts_elements_15k)))\n",
    "unique_elements_20k, counts_elements_20k = np.unique(y_train_20k, return_counts = True)\n",
    "print(\"20000 단어 사용 시 각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements_20k, counts_elements_20k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gzjQiz9Gbr3N"
   },
   "outputs": [],
   "source": [
    "word_index_n = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index_5k = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index_15k = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "word_index_20k = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "xu9W0aMYbzTE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 \n",
      "word_index_n['the'] :  1\n",
      "word_index_n['it'] :  13\n",
      "word_index_n['they'] :  74\n",
      "word_index_n['i'] :  265\n",
      "word_index_n['you'] :  1025\n",
      "----------------------------------\n",
      "5000 단어 사용 시 \n",
      "word_index_5k['the'] :  1\n",
      "word_index_5k['it'] :  13\n",
      "word_index_5k['they'] :  74\n",
      "word_index_5k['i'] :  265\n",
      "word_index_5k['you'] :  1025\n",
      "----------------------------------\n",
      "15000 단어 사용 시 \n",
      "word_index_15k['the'] :  1\n",
      "word_index_15k['it'] :  13\n",
      "word_index_15k['they'] :  74\n",
      "word_index_15k['i'] :  265\n",
      "word_index_15k['you'] :  1025\n",
      "----------------------------------\n",
      "20000 단어 사용 시 \n",
      "word_index_20k['the'] :  1\n",
      "word_index_20k['it'] :  13\n",
      "word_index_20k['they'] :  74\n",
      "word_index_20k['i'] :  265\n",
      "word_index_20k['you'] :  1025\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 \")\n",
    "print(\"word_index_n['the'] : \", word_index_n['the'])\n",
    "print(\"word_index_n['it'] : \", word_index_n['it'])\n",
    "print(\"word_index_n['they'] : \", word_index_n['they'])\n",
    "print(\"word_index_n['i'] : \", word_index_n['i'])\n",
    "print(\"word_index_n['you'] : \", word_index_n['you'])\n",
    "print(\"----------------------------------\")\n",
    "print(\"5000 단어 사용 시 \")\n",
    "print(\"word_index_5k['the'] : \", word_index_5k['the'])\n",
    "print(\"word_index_5k['it'] : \", word_index_5k['it'])\n",
    "print(\"word_index_5k['they'] : \", word_index_5k['they'])\n",
    "print(\"word_index_5k['i'] : \", word_index_5k['i'])\n",
    "print(\"word_index_5k['you'] : \", word_index_5k['you'])\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 \")\n",
    "print(\"word_index_15k['the'] : \", word_index_15k['the'])\n",
    "print(\"word_index_15k['it'] : \", word_index_15k['it'])\n",
    "print(\"word_index_15k['they'] : \", word_index_15k['they'])\n",
    "print(\"word_index_15k['i'] : \", word_index_15k['i'])\n",
    "print(\"word_index_15k['you'] : \", word_index_15k['you'])\n",
    "print(\"----------------------------------\")\n",
    "print(\"20000 단어 사용 시 \")\n",
    "print(\"word_index_20k['the'] : \", word_index_20k['the'])\n",
    "print(\"word_index_20k['it'] : \", word_index_20k['it'])\n",
    "print(\"word_index_20k['they'] : \", word_index_20k['they'])\n",
    "print(\"word_index_20k['i'] : \", word_index_20k['i'])\n",
    "print(\"word_index_20k['you'] : \", word_index_20k['you'])\n",
    "print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "N5mvbdsDcMqx"
   },
   "outputs": [],
   "source": [
    "index_to_word_n = { index+3 : word for word, index in word_index_n.items() }\n",
    "index_to_word_5k = { index+3 : word for word, index in word_index_5k.items() }\n",
    "index_to_word_15k = { index+3 : word for word, index in word_index_15k.items() }\n",
    "index_to_word_20k = { index+3 : word for word, index in word_index_20k.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1NVBvwHMcYzu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 \n",
      "index_to_word_n[4] :  the\n",
      "index_to_word_n[16] :  it\n",
      "index_to_word_n[77] :  they\n",
      "index_to_word_n[268] :  i\n",
      "index_to_word_n[1028] :  you\n",
      "----------------------------------\n",
      "5000 단어 사용 시 \n",
      "index_to_word_5k[4] :  the\n",
      "index_to_word_5k[16] :  it\n",
      "index_to_word_5k[77] :  they\n",
      "index_to_word_5k[268] :  i\n",
      "index_to_word_5k[1028] :  you\n",
      "----------------------------------\n",
      "15000 단어 사용 시 \n",
      "index_to_word_15k[4] :  the\n",
      "index_to_word_15k[16] :  it\n",
      "index_to_word_15k[77] :  they\n",
      "index_to_word_15k[268] :  i\n",
      "index_to_word_15k[1028] :  you\n",
      "----------------------------------\n",
      "20000 단어 사용 시 \n",
      "index_to_word_20k[4] :  the\n",
      "index_to_word_20k[16] :  it\n",
      "index_to_word_20k[77] :  they\n",
      "index_to_word_20k[268] :  i\n",
      "index_to_word_20k[1028] :  you\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 \")\n",
    "print('index_to_word_n[4] : ', index_to_word_n[4])\n",
    "print('index_to_word_n[16] : ', index_to_word_n[16])\n",
    "print('index_to_word_n[77] : ', index_to_word_n[77])\n",
    "print('index_to_word_n[268] : ', index_to_word_n[268])\n",
    "print('index_to_word_n[1028] : ', index_to_word_n[1028])\n",
    "print(\"----------------------------------\")\n",
    "print(\"5000 단어 사용 시 \")\n",
    "print('index_to_word_5k[4] : ', index_to_word_5k[4])\n",
    "print('index_to_word_5k[16] : ', index_to_word_5k[16])\n",
    "print('index_to_word_5k[77] : ', index_to_word_5k[77])\n",
    "print('index_to_word_5k[268] : ', index_to_word_5k[268])\n",
    "print('index_to_word_5k[1028] : ', index_to_word_5k[1028])\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 \")\n",
    "print('index_to_word_15k[4] : ', index_to_word_15k[4])\n",
    "print('index_to_word_15k[16] : ', index_to_word_15k[16])\n",
    "print('index_to_word_15k[77] : ', index_to_word_15k[77])\n",
    "print('index_to_word_15k[268] : ', index_to_word_15k[268])\n",
    "print('index_to_word_15k[1028] : ', index_to_word_15k[1028])\n",
    "print(\"----------------------------------\")\n",
    "print(\"20000 단어 사용 시 \")\n",
    "print('index_to_word_20k[4] : ', index_to_word_20k[4])\n",
    "print('index_to_word_20k[16] : ', index_to_word_20k[16])\n",
    "print('index_to_word_20k[77] : ', index_to_word_20k[77])\n",
    "print('index_to_word_20k[268] : ', index_to_word_20k[268])\n",
    "print('index_to_word_20k[1028] : ', index_to_word_20k[1028])\n",
    "print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TmB0R7Qrc2HV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word_n[index]=token\n",
    "  index_to_word_5k[index]=token\n",
    "  index_to_word_15k[index]=token\n",
    "  index_to_word_20k[index]=token\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_l-rEGn8c__S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 \n",
      "<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "----------------------------------\n",
      "5000 단어 사용 시 \n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "----------------------------------\n",
      "15000 단어 사용 시 \n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "----------------------------------\n",
      "20000 단어 사용 시 \n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_n[index] for index in x_train_n[0]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"5000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_5k[index] for index in x_train_5k[0]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_15k[index] for index in x_train_15k[0]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"20000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_20k[index] for index in x_train_20k[0]]))\n",
    "print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cC9cq3SIdQkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 \n",
      "the transaction is expected to be completed\n",
      "the staffing is expected to be completed\n",
      "----------------------------------\n",
      "5000 단어 사용 시 \n",
      "the transaction is expected to be completed\n",
      "the staffing is expected to be completed\n",
      "----------------------------------\n",
      "15000 단어 사용 시 \n",
      "the transaction is expected to be completed\n",
      "the staffing is expected to be completed\n",
      "----------------------------------\n",
      "20000 단어 사용 시 \n",
      "the transaction is expected to be completed\n",
      "the staffing is expected to be completed\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_n[index] for index in [4, 587, 23, 133, 6, 30, 515]]))\n",
    "print(' '.join([index_to_word_n[index] for index in [4, 12000, 23, 133, 6, 30, 515]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"5000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_5k[index] for index in [4, 587, 23, 133, 6, 30, 515]]))\n",
    "print(' '.join([index_to_word_5k[index] for index in [4, 12000, 23, 133, 6, 30, 515]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"15000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_15k[index] for index in [4, 587, 23, 133, 6, 30, 515]]))\n",
    "print(' '.join([index_to_word_15k[index] for index in [4, 12000, 23, 133, 6, 30, 515]]))\n",
    "print(\"----------------------------------\")\n",
    "print(\"20000 단어 사용 시 \")\n",
    "print(' '.join([index_to_word_20k[index] for index in [4, 587, 23, 133, 6, 30, 515]]))\n",
    "print(' '.join([index_to_word_20k[index] for index in [4, 12000, 23, 133, 6, 30, 515]]))\n",
    "print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ufTpXiIjzgzF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_n)):\n",
    "    t = ' '.join([index_to_word_n[index] for index in x_train_n[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_n = decoded\n",
    "print(len(x_train_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "08NyXvBRzxki"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test_n)):\n",
    "    t = ' '.join([index_to_word_n[index] for index in x_test_n[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_n = decoded\n",
    "print(len(x_test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gxTBizJOxYPO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_5k)):\n",
    "    t = ' '.join([index_to_word_5k[index] for index in x_train_5k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_5k = decoded\n",
    "print(len(x_train_5k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "0K9niNSJxU9s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test_5k)):\n",
    "    t = ' '.join([index_to_word_5k[index] for index in x_test_5k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_5k = decoded\n",
    "print(len(x_test_5k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "EAfCl7EixkA5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_15k)):\n",
    "    t = ' '.join([index_to_word_15k[index] for index in x_train_15k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_15k = decoded\n",
    "print(len(x_train_15k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "phL0GQRwxj1q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test_15k)):\n",
    "    t = ' '.join([index_to_word_15k[index] for index in x_test_15k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_15k = decoded\n",
    "print(len(x_test_15k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "SWbwUf6fxjpf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_train_20k)):\n",
    "    t = ' '.join([index_to_word_20k[index] for index in x_train_20k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train_20k = decoded\n",
    "print(len(x_train_20k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "63hgGhZkxjLy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test_20k)):\n",
    "    t = ' '.join([index_to_word_20k[index] for index in x_test_20k[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test_20k = decoded\n",
    "print(len(x_test_20k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "g-UukmZHzixT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 :  (8982, 26506)\n",
      "5000 단어 사용 시 :  (8982, 4867)\n",
      "15000 단어 사용 시 :  (8982, 14227)\n",
      "20000 단어 사용 시 :  (8982, 18479)\n"
     ]
    }
   ],
   "source": [
    "dtmvector_n = CountVectorizer()\n",
    "x_train_dtm_n = dtmvector_n.fit_transform(x_train_n)\n",
    "print(\"모든 단어 사용 시 : \", x_train_dtm_n.shape)\n",
    "dtmvector_5k = CountVectorizer()\n",
    "x_train_dtm_5k = dtmvector_5k.fit_transform(x_train_5k)\n",
    "print(\"5000 단어 사용 시 : \", x_train_dtm_5k.shape)\n",
    "dtmvector_15k = CountVectorizer()\n",
    "x_train_dtm_15k = dtmvector_15k.fit_transform(x_train_15k)\n",
    "print(\"15000 단어 사용 시 : \", x_train_dtm_15k.shape)\n",
    "dtmvector_20k = CountVectorizer()\n",
    "x_train_dtm_20k = dtmvector_20k.fit_transform(x_train_20k)\n",
    "print(\"20000 단어 사용 시 : \", x_train_dtm_20k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cQCyw0RPzoj_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 :  (8982, 26506)\n",
      "5000 단어 사용 시 :  (8982, 4867)\n",
      "15000 단어 사용 시 :  (8982, 14227)\n",
      "20000 단어 사용 시 :  (8982, 18479)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer_n = TfidfTransformer()\n",
    "tfidfv_n = tfidf_transformer_n.fit_transform(x_train_dtm_n)\n",
    "print(\"모든 단어 사용 시 : \", tfidfv_n.shape)\n",
    "tfidf_transformer_5k = TfidfTransformer()\n",
    "tfidfv_5k = tfidf_transformer_5k.fit_transform(x_train_dtm_5k)\n",
    "print(\"5000 단어 사용 시 : \", tfidfv_5k.shape)\n",
    "tfidf_transformer_15k = TfidfTransformer()\n",
    "tfidfv_15k = tfidf_transformer_15k.fit_transform(x_train_dtm_15k)\n",
    "print(\"15000 단어 사용 시 : \", tfidfv_15k.shape)\n",
    "tfidf_transformer_20k = TfidfTransformer()\n",
    "tfidfv_20k = tfidf_transformer_20k.fit_transform(x_train_dtm_20k)\n",
    "print(\"20000 단어 사용 시 : \", tfidfv_20k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "zIyLu_wYzqMV"
   },
   "outputs": [],
   "source": [
    "x_test_dtm_n = dtmvector_n.transform(x_test_n)\n",
    "tfidfv_test_n = tfidf_transformer_n.transform(x_test_dtm_n) \n",
    "x_test_dtm_5k = dtmvector_5k.transform(x_test_5k)\n",
    "tfidfv_test_5k = tfidf_transformer_5k.transform(x_test_dtm_5k) \n",
    "x_test_dtm_15k = dtmvector_15k.transform(x_test_15k)\n",
    "tfidfv_test_15k = tfidf_transformer_15k.transform(x_test_dtm_15k) \n",
    "x_test_dtm_20k = dtmvector_20k.transform(x_test_20k)\n",
    "tfidfv_test_20k = tfidf_transformer_20k.transform(x_test_dtm_20k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Ce5zLcZQzsla"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.5997328584149599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.79      0.21      0.33       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.72      0.92      0.81       813\n",
      "           4       0.45      0.96      0.61       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.00      0.00      0.00        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.80      0.29      0.42        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.75      0.18      0.29        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.73      0.58      0.64       133\n",
      "          20       0.00      0.00      0.00        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       0.00      0.00      0.00        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.60      2246\n",
      "   macro avg       0.09      0.07      0.07      2246\n",
      "weighted avg       0.50      0.60      0.50      2246\n",
      "\n",
      "CNB 정확도: 0.7649154051647373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.50      0.63        12\n",
      "           1       0.63      0.88      0.73       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.87      0.91      0.89       813\n",
      "           4       0.75      0.93      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.43      0.08      0.13        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.96      0.73      0.83        30\n",
      "          11       0.55      0.67      0.61        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.62      0.54      0.58        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.11      0.18         9\n",
      "          16       0.67      0.77      0.71        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.65      0.55      0.59        20\n",
      "          19       0.55      0.80      0.65       133\n",
      "          20       0.89      0.23      0.36        70\n",
      "          21       0.84      0.59      0.70        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.71      0.42      0.53        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.83      0.61      0.70        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.33      0.10      0.15        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.31      0.47        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       1.00      0.20      0.33         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.76      2246\n",
      "   macro avg       0.62      0.42      0.46      2246\n",
      "weighted avg       0.75      0.76      0.73      2246\n",
      "\n",
      "로지스틱 회귀 정확도: 0.813446126447017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.75      0.80      0.77       105\n",
      "           2       0.70      0.70      0.70        20\n",
      "           3       0.93      0.93      0.93       813\n",
      "           4       0.81      0.87      0.84       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.93      1.00      0.97        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.71      0.69        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.66      0.73      0.70        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.61      0.62      0.61        37\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       0.71      0.56      0.63         9\n",
      "          16       0.71      0.77      0.74        99\n",
      "          17       0.67      0.50      0.57        12\n",
      "          18       0.76      0.65      0.70        20\n",
      "          19       0.69      0.70      0.69       133\n",
      "          20       0.60      0.49      0.54        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.69      0.75      0.72        12\n",
      "          24       0.62      0.53      0.57        19\n",
      "          25       0.92      0.74      0.82        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.75      0.30      0.43        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       0.89      0.67      0.76        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       1.00      0.29      0.44         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.42      0.45      0.43        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.40      0.44         5\n",
      "          40       1.00      0.30      0.46        10\n",
      "          41       0.83      0.62      0.71         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.76      0.64      0.67      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.719946571682992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.58      0.64        12\n",
      "           1       0.60      0.66      0.63       105\n",
      "           2       0.59      0.65      0.62        20\n",
      "           3       0.90      0.89      0.90       813\n",
      "           4       0.78      0.80      0.79       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.62      0.57      0.59        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.50      0.61      0.55        38\n",
      "           9       0.75      0.48      0.59        25\n",
      "          10       0.62      0.60      0.61        30\n",
      "          11       0.56      0.65      0.60        83\n",
      "          12       0.30      0.23      0.26        13\n",
      "          13       0.41      0.35      0.38        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.57      0.44      0.50         9\n",
      "          16       0.58      0.63      0.60        99\n",
      "          17       0.50      0.25      0.33        12\n",
      "          18       0.53      0.50      0.51        20\n",
      "          19       0.59      0.60      0.59       133\n",
      "          20       0.41      0.40      0.41        70\n",
      "          21       0.65      0.63      0.64        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.25      0.17      0.20        12\n",
      "          24       0.37      0.37      0.37        19\n",
      "          25       0.72      0.58      0.64        31\n",
      "          26       1.00      0.62      0.77         8\n",
      "          27       0.50      0.25      0.33         4\n",
      "          28       0.33      0.20      0.25        10\n",
      "          29       0.29      0.50      0.36         4\n",
      "          30       0.25      0.08      0.12        12\n",
      "          31       0.45      0.38      0.42        13\n",
      "          32       0.60      0.60      0.60        10\n",
      "          33       0.67      0.80      0.73         5\n",
      "          34       0.50      0.57      0.53         7\n",
      "          35       0.75      0.50      0.60         6\n",
      "          36       0.23      0.27      0.25        11\n",
      "          37       0.20      0.50      0.29         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.20      0.29         5\n",
      "          40       0.57      0.40      0.47        10\n",
      "          41       0.43      0.38      0.40         8\n",
      "          42       0.40      0.67      0.50         3\n",
      "          43       0.36      0.67      0.47         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.72      2246\n",
      "   macro avg       0.49      0.48      0.47      2246\n",
      "weighted avg       0.72      0.72      0.72      2246\n",
      "\n",
      "결정 트리 정확도: 0.6211041852181657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.69      0.43      0.53       105\n",
      "           2       0.75      0.45      0.56        20\n",
      "           3       0.94      0.85      0.89       813\n",
      "           4       0.40      0.89      0.55       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.16      0.28        25\n",
      "          10       0.89      0.80      0.84        30\n",
      "          11       0.58      0.60      0.59        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.61      0.83      0.70        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.67      0.41      0.50       133\n",
      "          20       0.83      0.07      0.13        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       0.60      0.19      0.29        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.22      0.15      0.15      2246\n",
      "weighted avg       0.62      0.62      0.58      2246\n",
      "\n",
      "랜덤 포레스트 정확도: 0.6544968833481746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        12\n",
      "           1       0.35      0.60      0.44       105\n",
      "           2       0.32      0.40      0.36        20\n",
      "           3       0.82      0.89      0.85       813\n",
      "           4       0.62      0.84      0.71       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.67      0.43      0.52        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.51      0.47      0.49        38\n",
      "           9       1.00      0.28      0.44        25\n",
      "          10       0.46      0.20      0.28        30\n",
      "          11       0.56      0.64      0.60        83\n",
      "          12       0.40      0.15      0.22        13\n",
      "          13       0.33      0.16      0.22        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.59      0.46      0.52        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.44      0.20      0.28        20\n",
      "          19       0.61      0.50      0.55       133\n",
      "          20       0.51      0.33      0.40        70\n",
      "          21       0.55      0.22      0.32        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.33      0.08      0.13        12\n",
      "          24       0.33      0.05      0.09        19\n",
      "          25       1.00      0.23      0.37        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.10      0.18        10\n",
      "          33       1.00      0.40      0.57         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.43      0.27      0.33        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.30      0.46        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.75      0.50      0.60         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.65      2246\n",
      "   macro avg       0.40      0.25      0.28      2246\n",
      "weighted avg       0.63      0.65      0.62      2246\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.4301           11.03m\n",
      "         2       76760.8864           11.04m\n",
      "         3   766490025.2967           10.99m\n",
      "         4 660857139232122368.0000           10.89m\n",
      "         5 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.81m\n",
      "         6 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.70m\n",
      "         7 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.60m\n",
      "         8 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.50m\n",
      "         9 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.39m\n",
      "        10 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.28m\n",
      "        11 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.17m\n",
      "        12 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000           10.06m\n",
      "        13 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.96m\n",
      "        14 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.85m\n",
      "        15 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.73m\n",
      "        16 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.62m\n",
      "        17 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.51m\n",
      "        18 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.39m\n",
      "        19 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.28m\n",
      "        20 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.16m\n",
      "        21 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            9.04m\n",
      "        22 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            8.92m\n",
      "        23 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            8.81m\n",
      "        24 1006529060407114004275646732312951615311370376755613476759245377256674837692003341988813591601665584394912965173495998495951159296.0000            8.69m\n",
      "        25 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.58m\n",
      "        26 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.46m\n",
      "        27 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.36m\n",
      "        28 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.25m\n",
      "        29 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.13m\n",
      "        30 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            8.02m\n",
      "        31 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.90m\n",
      "        32 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.79m\n",
      "        33 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.67m\n",
      "        34 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.56m\n",
      "        35 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.44m\n",
      "        36 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.33m\n",
      "        37 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.21m\n",
      "        38 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.10m\n",
      "        39 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.98m\n",
      "        40 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.87m\n",
      "        41 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.75m\n",
      "        42 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.64m\n",
      "        43 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.52m\n",
      "        44 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.41m\n",
      "        45 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.29m\n",
      "        46 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.18m\n",
      "        47 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            6.06m\n",
      "        48 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.95m\n",
      "        49 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.83m\n",
      "        50 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.72m\n",
      "        51 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.61m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        52 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.49m\n",
      "        53 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.38m\n",
      "        54 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.26m\n",
      "        55 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.15m\n",
      "        56 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            5.04m\n",
      "        57 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.93m\n",
      "        58 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.83m\n",
      "        59 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.72m\n",
      "        60 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.61m\n",
      "        61 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.50m\n",
      "        62 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.40m\n",
      "        63 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.29m\n",
      "        64 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.18m\n",
      "        65 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            4.06m\n",
      "        66 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.95m\n",
      "        67 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.84m\n",
      "        68 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.73m\n",
      "        69 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.61m\n",
      "        70 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.50m\n",
      "        71 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.39m\n",
      "        72 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.27m\n",
      "        73 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.16m\n",
      "        74 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            3.05m\n",
      "        75 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.93m\n",
      "        76 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.82m\n",
      "        77 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.70m\n",
      "        78 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.59m\n",
      "        79 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.47m\n",
      "        80 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.35m\n",
      "        81 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.24m\n",
      "        82 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.12m\n",
      "        83 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            2.01m\n",
      "        84 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.89m\n",
      "        85 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.77m\n",
      "        86 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.65m\n",
      "        87 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.54m\n",
      "        88 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.42m\n",
      "        89 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.30m\n",
      "        90 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.18m\n",
      "        91 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            1.07m\n",
      "        92 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           56.93s\n",
      "        93 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           49.84s\n",
      "        94 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           42.74s\n",
      "        95 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           35.64s\n",
      "        96 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           28.52s\n",
      "        97 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           21.40s\n",
      "        98 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000           14.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        99 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            7.14s\n",
      "       100 7935486330861459413268209935908863185564832687635547920920276400843855648137909550861590845608894276096734983386906163942311234165539923296256.0000            0.00s\n",
      "그래디언트 부스팅 트리 정확도: 0.7707034728406055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.50      0.55        12\n",
      "           1       0.81      0.71      0.76       105\n",
      "           2       0.58      0.70      0.64        20\n",
      "           3       0.87      0.92      0.89       813\n",
      "           4       0.78      0.86      0.82       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.77      0.71      0.74        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.60      0.63      0.62        38\n",
      "           9       0.91      0.80      0.85        25\n",
      "          10       0.79      0.77      0.78        30\n",
      "          11       0.61      0.65      0.63        83\n",
      "          12       0.50      0.46      0.48        13\n",
      "          13       0.46      0.32      0.38        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.25      0.11      0.15         9\n",
      "          16       0.72      0.71      0.71        99\n",
      "          17       0.83      0.42      0.56        12\n",
      "          18       0.59      0.50      0.54        20\n",
      "          19       0.71      0.64      0.67       133\n",
      "          20       0.64      0.41      0.50        70\n",
      "          21       0.61      0.63      0.62        27\n",
      "          22       0.33      0.14      0.20         7\n",
      "          23       0.62      0.67      0.64        12\n",
      "          24       0.69      0.47      0.56        19\n",
      "          25       0.83      0.65      0.73        31\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       0.33      0.50      0.40         4\n",
      "          28       0.25      0.20      0.22        10\n",
      "          29       0.43      0.75      0.55         4\n",
      "          30       0.36      0.42      0.38        12\n",
      "          31       0.50      0.54      0.52        13\n",
      "          32       1.00      1.00      1.00        10\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       0.60      0.43      0.50         7\n",
      "          35       0.33      0.17      0.22         6\n",
      "          36       0.50      0.64      0.56        11\n",
      "          37       0.50      1.00      0.67         2\n",
      "          38       0.33      0.33      0.33         3\n",
      "          39       0.33      0.20      0.25         5\n",
      "          40       0.83      0.50      0.62        10\n",
      "          41       0.62      0.62      0.62         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.43      0.50      0.46         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.62      0.57      0.57      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyride/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 정확도: 0.8192341941228851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.80      0.77      0.79       105\n",
      "           2       0.67      0.80      0.73        20\n",
      "           3       0.93      0.94      0.93       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.87      0.93      0.90        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.69      0.71      0.70        38\n",
      "           9       0.80      0.80      0.80        25\n",
      "          10       0.90      0.90      0.90        30\n",
      "          11       0.67      0.71      0.69        83\n",
      "          12       0.60      0.46      0.52        13\n",
      "          13       0.69      0.65      0.67        37\n",
      "          14       0.29      1.00      0.44         2\n",
      "          15       0.40      0.22      0.29         9\n",
      "          16       0.73      0.76      0.74        99\n",
      "          17       0.75      0.50      0.60        12\n",
      "          18       0.73      0.55      0.63        20\n",
      "          19       0.71      0.71      0.71       133\n",
      "          20       0.66      0.50      0.57        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       1.00      0.14      0.25         7\n",
      "          23       0.62      0.67      0.64        12\n",
      "          24       0.73      0.58      0.65        19\n",
      "          25       0.92      0.77      0.84        31\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.33      0.30      0.32        10\n",
      "          29       0.50      1.00      0.67         4\n",
      "          30       0.54      0.58      0.56        12\n",
      "          31       0.82      0.69      0.75        13\n",
      "          32       1.00      1.00      1.00        10\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       0.80      0.57      0.67         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.54      0.64      0.58        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       1.00      0.40      0.57        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.83      0.83      0.83         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.73      0.66      0.66      2246\n",
      "weighted avg       0.82      0.82      0.82      2246\n",
      "\n",
      "모든 단어 사용 시 수행시간 : 0:25:23\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "mod_n, cb_n, lr_n, lsvc_n, tree_n, forest_n, grbt_n, voting_classifier_n = train_ml(tfidfv_n, \n",
    "                                                                                    y_train_n, \n",
    "                                                                                    tfidfv_test_n, \n",
    "                                                                                    y_test_n)\n",
    "\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print('모든 단어 사용 시 수행시간 :', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-qVHDHyTzKx7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6731967943009796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.50      0.80      0.62       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.86      0.89      0.87       813\n",
      "           4       0.59      0.95      0.73       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.28      0.44        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.48      0.73      0.58        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       1.00      0.14      0.24        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.60      0.66      0.62        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.51      0.81      0.63       133\n",
      "          20       0.90      0.13      0.23        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       1.00      0.06      0.12        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.16      0.12      0.11      2246\n",
      "weighted avg       0.60      0.67      0.60      2246\n",
      "\n",
      "CNB 정확도: 0.7707034728406055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.58      0.70        12\n",
      "           1       0.63      0.86      0.73       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.91      0.89      0.90       813\n",
      "           4       0.74      0.92      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.86      0.86        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.57      0.21      0.31        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.54      0.76      0.63        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.69      0.59      0.64        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.67      0.79      0.72        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.55      0.60      0.57        20\n",
      "          19       0.56      0.80      0.66       133\n",
      "          20       0.79      0.33      0.46        70\n",
      "          21       0.78      0.67      0.72        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.67      0.33      0.44        12\n",
      "          24       0.67      0.11      0.18        19\n",
      "          25       0.86      0.77      0.81        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.33      0.20      0.25        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.15      0.27        13\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.76      0.77      0.75      2246\n",
      "\n",
      "로지스틱 회귀 정확도: 0.8058771148708815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.77      0.80      0.79       105\n",
      "           2       0.74      0.85      0.79        20\n",
      "           3       0.91      0.93      0.92       813\n",
      "           4       0.81      0.87      0.84       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.64      0.74      0.68        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.64      0.73      0.68        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.64      0.62      0.63        37\n",
      "          14       0.50      0.50      0.50         2\n",
      "          15       0.83      0.56      0.67         9\n",
      "          16       0.67      0.73      0.70        99\n",
      "          17       0.82      0.75      0.78        12\n",
      "          18       0.80      0.60      0.69        20\n",
      "          19       0.66      0.68      0.67       133\n",
      "          20       0.61      0.47      0.53        70\n",
      "          21       0.62      0.78      0.69        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.55      0.50      0.52        12\n",
      "          24       0.69      0.58      0.63        19\n",
      "          25       0.91      0.65      0.75        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.67      0.40      0.50        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       1.00      0.42      0.59        12\n",
      "          31       0.70      0.54      0.61        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       1.00      0.29      0.44         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.38      0.27      0.32        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.40      0.40      0.40         5\n",
      "          40       0.75      0.30      0.43        10\n",
      "          41       0.83      0.62      0.71         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.67      1.00      0.80         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.73      0.61      0.64      2246\n",
      "weighted avg       0.80      0.81      0.80      2246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.7292965271593945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67        12\n",
      "           1       0.67      0.61      0.64       105\n",
      "           2       0.55      0.55      0.55        20\n",
      "           3       0.89      0.89      0.89       813\n",
      "           4       0.82      0.82      0.82       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.61      0.79      0.69        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.51      0.61      0.55        38\n",
      "           9       0.61      0.68      0.64        25\n",
      "          10       0.62      0.67      0.65        30\n",
      "          11       0.59      0.66      0.62        83\n",
      "          12       0.27      0.23      0.25        13\n",
      "          13       0.45      0.51      0.48        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.80      0.44      0.57         9\n",
      "          16       0.59      0.66      0.62        99\n",
      "          17       0.43      0.25      0.32        12\n",
      "          18       0.59      0.50      0.54        20\n",
      "          19       0.62      0.64      0.63       133\n",
      "          20       0.54      0.43      0.48        70\n",
      "          21       0.44      0.56      0.49        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.42      0.42      0.42        12\n",
      "          24       0.31      0.26      0.29        19\n",
      "          25       0.83      0.61      0.70        31\n",
      "          26       0.83      0.62      0.71         8\n",
      "          27       0.33      0.25      0.29         4\n",
      "          28       0.25      0.10      0.14        10\n",
      "          29       0.12      0.25      0.17         4\n",
      "          30       0.43      0.25      0.32        12\n",
      "          31       0.25      0.23      0.24        13\n",
      "          32       0.43      0.60      0.50        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       0.38      0.43      0.40         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.40      0.36      0.38        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.30      0.30      0.30        10\n",
      "          41       0.44      0.50      0.47         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.36      0.67      0.47         6\n",
      "          44       0.83      1.00      0.91         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.73      2246\n",
      "   macro avg       0.51      0.47      0.47      2246\n",
      "weighted avg       0.73      0.73      0.73      2246\n",
      "\n",
      "결정 트리 정확도: 0.6179875333926982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.72      0.40      0.52       105\n",
      "           2       0.60      0.45      0.51        20\n",
      "           3       0.94      0.84      0.89       813\n",
      "           4       0.39      0.91      0.55       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       1.00      0.57      0.73        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.88      0.88      0.88        25\n",
      "          10       0.87      0.87      0.87        30\n",
      "          11       0.62      0.48      0.54        83\n",
      "          12       0.17      0.08      0.11        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.60      0.82      0.69        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.62      0.26      0.37       133\n",
      "          20       0.33      0.03      0.05        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       1.00      0.05      0.10        19\n",
      "          25       0.86      0.19      0.32        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.83      1.00      0.91         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.24      0.17      0.18      2246\n",
      "weighted avg       0.61      0.62      0.57      2246\n",
      "\n",
      "랜덤 포레스트 정확도: 0.701246660730187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.42      0.33        12\n",
      "           1       0.42      0.78      0.55       105\n",
      "           2       0.44      0.35      0.39        20\n",
      "           3       0.84      0.90      0.87       813\n",
      "           4       0.68      0.84      0.75       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.86      0.43      0.57        14\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.59      0.53      0.56        38\n",
      "           9       0.71      0.40      0.51        25\n",
      "          10       0.89      0.53      0.67        30\n",
      "          11       0.57      0.69      0.62        83\n",
      "          12       0.33      0.15      0.21        13\n",
      "          13       0.46      0.32      0.38        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.11      0.20         9\n",
      "          16       0.70      0.67      0.68        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.60      0.45      0.51        20\n",
      "          19       0.62      0.64      0.63       133\n",
      "          20       0.46      0.33      0.38        70\n",
      "          21       0.65      0.41      0.50        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.75      0.25      0.38        12\n",
      "          24       0.33      0.05      0.09        19\n",
      "          25       0.87      0.42      0.57        31\n",
      "          26       1.00      0.12      0.22         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.33      0.25      0.29         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.30      0.46        10\n",
      "          33       1.00      0.20      0.33         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.33      0.09      0.14        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.25      0.12      0.17         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       1.00      0.33      0.50         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.70      2246\n",
      "   macro avg       0.54      0.31      0.36      2246\n",
      "weighted avg       0.69      0.70      0.68      2246\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.4697           10.87m\n",
      "         2     2131099.0239           10.86m\n",
      "         3 113352934366748750033493137947714414201794552363528671409179356940992512.0000           10.84m\n",
      "         4 645005367195105573487290209089081189090170195029150070319832395667206596719018218881024.0000           10.72m\n",
      "         5 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.60m\n",
      "         6 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.49m\n",
      "         7 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.37m\n",
      "         8 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.27m\n",
      "         9 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.15m\n",
      "        10 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000           10.04m\n",
      "        11 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.92m\n",
      "        12 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.81m\n",
      "        13 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.72m\n",
      "        14 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.60m\n",
      "        15 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.49m\n",
      "        16 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.38m\n",
      "        17 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.26m\n",
      "        18 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.15m\n",
      "        19 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            9.04m\n",
      "        20 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.92m\n",
      "        21 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.81m\n",
      "        22 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.70m\n",
      "        23 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.59m\n",
      "        24 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.48m\n",
      "        25 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.36m\n",
      "        26 443067299530301659980374363525949995629695549691559890285869350923592723545213280554158712204202745088665306932510573934053386280801140736.0000            8.25m\n",
      "        27 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            8.14m\n",
      "        28 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            8.03m\n",
      "        29 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.92m\n",
      "        30 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.81m\n",
      "        31 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.69m\n",
      "        32 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.58m\n",
      "        33 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.47m\n",
      "        34 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.36m\n",
      "        35 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.25m\n",
      "        36 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.14m\n",
      "        37 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            7.02m\n",
      "        38 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.91m\n",
      "        39 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.80m\n",
      "        40 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.69m\n",
      "        41 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.58m\n",
      "        42 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.47m\n",
      "        43 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.36m\n",
      "        44 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.25m\n",
      "        45 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.14m\n",
      "        46 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.03m\n",
      "        47 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.91m\n",
      "        48 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.80m\n",
      "        49 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.69m\n",
      "        50 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.58m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        51 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.47m\n",
      "        52 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.36m\n",
      "        53 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.25m\n",
      "        54 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.14m\n",
      "        55 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            5.02m\n",
      "        56 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.91m\n",
      "        57 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.80m\n",
      "        58 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.69m\n",
      "        59 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.58m\n",
      "        60 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.47m\n",
      "        61 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.36m\n",
      "        62 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.24m\n",
      "        63 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.13m\n",
      "        64 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            4.02m\n",
      "        65 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.91m\n",
      "        66 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.80m\n",
      "        67 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.69m\n",
      "        68 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.58m\n",
      "        69 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.46m\n",
      "        70 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.35m\n",
      "        71 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.24m\n",
      "        72 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.13m\n",
      "        73 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            3.02m\n",
      "        74 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.91m\n",
      "        75 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.79m\n",
      "        76 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.68m\n",
      "        77 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.57m\n",
      "        78 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.46m\n",
      "        79 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.35m\n",
      "        80 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.23m\n",
      "        81 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.12m\n",
      "        82 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            2.01m\n",
      "        83 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.90m\n",
      "        84 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.79m\n",
      "        85 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.68m\n",
      "        86 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.56m\n",
      "        87 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.45m\n",
      "        88 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.34m\n",
      "        89 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.23m\n",
      "        90 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.12m\n",
      "        91 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            1.01m\n",
      "        92 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           53.66s\n",
      "        93 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           46.95s\n",
      "        94 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           40.24s\n",
      "        95 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           33.54s\n",
      "        96 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           26.83s\n",
      "        97 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           20.12s\n",
      "        98 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000           13.41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        99 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            6.70s\n",
      "       100 443067299530302073140354857431324340576763070173459783038796203599354776450710327057778234898793885831921831754563603678560901920400080896.0000            0.00s\n",
      "그래디언트 부스팅 트리 정확도: 0.767586821015138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.80      0.68      0.73       105\n",
      "           2       0.70      0.70      0.70        20\n",
      "           3       0.90      0.90      0.90       813\n",
      "           4       0.76      0.83      0.79       474\n",
      "           5       0.14      0.20      0.17         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.64      0.66      0.65        38\n",
      "           9       0.91      0.84      0.87        25\n",
      "          10       0.87      0.87      0.87        30\n",
      "          11       0.62      0.66      0.64        83\n",
      "          12       0.46      0.46      0.46        13\n",
      "          13       0.55      0.43      0.48        37\n",
      "          14       0.08      0.50      0.14         2\n",
      "          15       0.33      0.22      0.27         9\n",
      "          16       0.72      0.77      0.75        99\n",
      "          17       0.33      0.33      0.33        12\n",
      "          18       0.61      0.55      0.58        20\n",
      "          19       0.71      0.65      0.68       133\n",
      "          20       0.56      0.44      0.50        70\n",
      "          21       0.67      0.67      0.67        27\n",
      "          22       0.50      0.14      0.22         7\n",
      "          23       0.36      0.42      0.38        12\n",
      "          24       0.71      0.63      0.67        19\n",
      "          25       0.91      0.65      0.75        31\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.40      0.50      0.44         4\n",
      "          28       0.38      0.30      0.33        10\n",
      "          29       0.22      0.50      0.31         4\n",
      "          30       0.38      0.42      0.40        12\n",
      "          31       0.60      0.46      0.52        13\n",
      "          32       0.88      0.70      0.78        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       0.50      0.29      0.36         7\n",
      "          35       1.00      0.50      0.67         6\n",
      "          36       0.67      0.55      0.60        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.25      0.33      0.29         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       0.71      0.50      0.59        10\n",
      "          41       0.44      0.50      0.47         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.50      0.67      0.57         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.60      0.59      0.58      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyride/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 정확도: 0.8161175422974176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.80      0.77      0.79       105\n",
      "           2       0.71      0.85      0.77        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       0.33      0.20      0.25         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       0.67      0.67      0.67         3\n",
      "           8       0.72      0.68      0.70        38\n",
      "           9       0.81      0.84      0.82        25\n",
      "          10       0.93      0.90      0.92        30\n",
      "          11       0.67      0.70      0.68        83\n",
      "          12       0.60      0.46      0.52        13\n",
      "          13       0.68      0.62      0.65        37\n",
      "          14       0.12      0.50      0.20         2\n",
      "          15       0.67      0.44      0.53         9\n",
      "          16       0.74      0.74      0.74        99\n",
      "          17       0.57      0.67      0.62        12\n",
      "          18       0.72      0.65      0.68        20\n",
      "          19       0.73      0.68      0.71       133\n",
      "          20       0.61      0.49      0.54        70\n",
      "          21       0.66      0.78      0.71        27\n",
      "          22       0.50      0.14      0.22         7\n",
      "          23       0.57      0.67      0.62        12\n",
      "          24       0.75      0.63      0.69        19\n",
      "          25       0.96      0.74      0.84        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.44      0.40      0.42        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       0.62      0.42      0.50        12\n",
      "          31       0.75      0.69      0.72        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       1.00      0.43      0.60         7\n",
      "          35       1.00      0.50      0.67         6\n",
      "          36       0.45      0.45      0.45        11\n",
      "          37       0.67      1.00      0.80         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.25      0.20      0.22         5\n",
      "          40       0.80      0.40      0.53        10\n",
      "          41       0.67      0.50      0.57         8\n",
      "          42       0.75      1.00      0.86         3\n",
      "          43       0.71      0.83      0.77         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.71      0.66      0.66      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n",
      "5000 단어 사용 시 수행시간 : 0:23:11\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod_5k, cb_5k, lr_5k, lsvc_5k, tree_5k, forest_5k, grbt_5k, voting_classifier_5k = train_ml(tfidfv_5k, \n",
    "                                                                                            y_train_5k, \n",
    "                                                                                            tfidfv_test_5k, \n",
    "                                                                                            y_test_5k)\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print('5000 단어 사용 시 수행시간 :', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "jAS4EiWtzf7i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6331255565449688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.77      0.53      0.63       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.77      0.91      0.84       813\n",
      "           4       0.47      0.96      0.63       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.04      0.08        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.69      0.40      0.50        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.75      0.41      0.53        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.64      0.74      0.69       133\n",
      "          20       1.00      0.01      0.03        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       0.00      0.00      0.00        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.63      2246\n",
      "   macro avg       0.13      0.09      0.09      2246\n",
      "weighted avg       0.55      0.63      0.55      2246\n",
      "\n",
      "CNB 정확도: 0.7720391807658059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.65      0.90      0.76       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.90      0.90      0.90       813\n",
      "           4       0.76      0.93      0.84       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.50      0.13      0.21        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.54      0.71      0.61        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.60      0.57      0.58        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.11      0.18         9\n",
      "          16       0.68      0.79      0.73        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.57      0.60      0.59        20\n",
      "          19       0.54      0.79      0.64       133\n",
      "          20       0.83      0.27      0.41        70\n",
      "          21       0.74      0.63      0.68        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.71      0.42      0.53        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.85      0.71      0.77        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.25      0.10      0.14        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.23      0.38        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       1.00      0.20      0.33         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.61      0.43      0.47      2246\n",
      "weighted avg       0.75      0.77      0.74      2246\n",
      "\n",
      "로지스틱 회귀 정확도: 0.8125556544968834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.76      0.80      0.78       105\n",
      "           2       0.71      0.75      0.73        20\n",
      "           3       0.92      0.93      0.93       813\n",
      "           4       0.80      0.87      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      1.00      0.97        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.65      0.74      0.69        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.64      0.75      0.69        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.64      0.62      0.63        37\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       0.83      0.56      0.67         9\n",
      "          16       0.71      0.76      0.74        99\n",
      "          17       0.78      0.58      0.67        12\n",
      "          18       0.81      0.65      0.72        20\n",
      "          19       0.68      0.71      0.69       133\n",
      "          20       0.62      0.47      0.54        70\n",
      "          21       0.65      0.81      0.72        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.67      0.67      0.67        12\n",
      "          24       0.65      0.58      0.61        19\n",
      "          25       0.96      0.74      0.84        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.75      0.30      0.43        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       1.00      0.50      0.67        12\n",
      "          31       0.78      0.54      0.64        13\n",
      "          32       1.00      0.70      0.82        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.50      0.27      0.35        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.20      0.29         5\n",
      "          40       1.00      0.30      0.46        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.75      0.63      0.66      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.7341941228851291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56        12\n",
      "           1       0.60      0.65      0.62       105\n",
      "           2       0.71      0.60      0.65        20\n",
      "           3       0.90      0.91      0.91       813\n",
      "           4       0.81      0.81      0.81       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.83      0.71      0.77        14\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.49      0.63      0.55        38\n",
      "           9       0.78      0.72      0.75        25\n",
      "          10       0.83      0.67      0.74        30\n",
      "          11       0.54      0.70      0.61        83\n",
      "          12       0.42      0.38      0.40        13\n",
      "          13       0.50      0.41      0.45        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.67      0.22      0.33         9\n",
      "          16       0.58      0.63      0.60        99\n",
      "          17       0.25      0.08      0.12        12\n",
      "          18       0.70      0.35      0.47        20\n",
      "          19       0.60      0.68      0.63       133\n",
      "          20       0.47      0.39      0.43        70\n",
      "          21       0.52      0.59      0.55        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.27      0.25      0.26        12\n",
      "          24       0.62      0.53      0.57        19\n",
      "          25       0.86      0.61      0.72        31\n",
      "          26       0.71      0.62      0.67         8\n",
      "          27       0.50      0.25      0.33         4\n",
      "          28       0.29      0.20      0.24        10\n",
      "          29       0.11      0.25      0.15         4\n",
      "          30       0.29      0.33      0.31        12\n",
      "          31       0.40      0.31      0.35        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.57      0.80      0.67         5\n",
      "          34       0.29      0.29      0.29         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.38      0.45      0.42        11\n",
      "          37       0.14      0.50      0.22         2\n",
      "          38       0.25      0.33      0.29         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.60      0.30      0.40        10\n",
      "          41       0.33      0.12      0.18         8\n",
      "          42       0.40      0.67      0.50         3\n",
      "          43       0.40      0.67      0.50         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.17      1.00      0.29         1\n",
      "\n",
      "    accuracy                           0.73      2246\n",
      "   macro avg       0.49      0.46      0.45      2246\n",
      "weighted avg       0.74      0.73      0.73      2246\n",
      "\n",
      "결정 트리 정확도: 0.6193232413178985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.73      0.42      0.53       105\n",
      "           2       0.75      0.45      0.56        20\n",
      "           3       0.94      0.83      0.88       813\n",
      "           4       0.40      0.91      0.55       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.90      0.64      0.75        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       0.88      0.88      0.88        25\n",
      "          10       0.86      0.80      0.83        30\n",
      "          11       0.64      0.49      0.56        83\n",
      "          12       0.14      0.08      0.10        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.61      0.82      0.70        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.60      0.29      0.39       133\n",
      "          20       0.40      0.03      0.05        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.50      0.05      0.10        19\n",
      "          25       0.86      0.19      0.32        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       1.00      1.00      1.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.17      0.18      2246\n",
      "weighted avg       0.61      0.62      0.58      2246\n",
      "\n",
      "랜덤 포레스트 정확도: 0.6714158504007124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33        12\n",
      "           1       0.42      0.69      0.52       105\n",
      "           2       0.13      0.10      0.11        20\n",
      "           3       0.81      0.90      0.85       813\n",
      "           4       0.65      0.85      0.74       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.83      0.36      0.50        14\n",
      "           7       0.50      0.67      0.57         3\n",
      "           8       0.62      0.53      0.57        38\n",
      "           9       0.71      0.40      0.51        25\n",
      "          10       0.60      0.20      0.30        30\n",
      "          11       0.45      0.51      0.47        83\n",
      "          12       0.60      0.23      0.33        13\n",
      "          13       0.40      0.22      0.28        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.55      0.46      0.50        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.55      0.30      0.39        20\n",
      "          19       0.65      0.56      0.60       133\n",
      "          20       0.60      0.37      0.46        70\n",
      "          21       0.56      0.33      0.42        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.50      0.17      0.25        12\n",
      "          24       0.33      0.05      0.09        19\n",
      "          25       1.00      0.35      0.52        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       1.00      0.10      0.18        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.20      0.33        10\n",
      "          33       1.00      0.60      0.75         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.40      0.18      0.25        11\n",
      "          37       1.00      0.50      0.67         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.50      0.12      0.20         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.33      0.17      0.22         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.43      0.26      0.30      2246\n",
      "weighted avg       0.65      0.67      0.64      2246\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.4326           11.70m\n",
      "         2       81331.2398           11.69m\n",
      "         3     5836811.5076           11.72m\n",
      "         4 63789339395313685793847548538268197034083221504000.0000           11.60m\n",
      "         5 196168839837262027401908577577888497468749556189708834227594295318514495389696.0000           11.47m\n",
      "         6 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           11.36m\n",
      "         7 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           11.25m\n",
      "         8 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           11.15m\n",
      "         9 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           11.04m\n",
      "        10 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.91m\n",
      "        11 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.80m\n",
      "        12 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.69m\n",
      "        13 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.56m\n",
      "        14 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.44m\n",
      "        15 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.32m\n",
      "        16 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.20m\n",
      "        17 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           10.08m\n",
      "        18 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.96m\n",
      "        19 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.84m\n",
      "        20 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.72m\n",
      "        21 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.60m\n",
      "        22 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.47m\n",
      "        23 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.35m\n",
      "        24 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.23m\n",
      "        25 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            9.11m\n",
      "        26 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.99m\n",
      "        27 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.87m\n",
      "        28 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.74m\n",
      "        29 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.62m\n",
      "        30 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.50m\n",
      "        31 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.38m\n",
      "        32 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.26m\n",
      "        33 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.13m\n",
      "        34 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            8.01m\n",
      "        35 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.89m\n",
      "        36 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.77m\n",
      "        37 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.65m\n",
      "        38 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.53m\n",
      "        39 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.41m\n",
      "        40 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.29m\n",
      "        41 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.16m\n",
      "        42 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.04m\n",
      "        43 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.92m\n",
      "        44 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.80m\n",
      "        45 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.68m\n",
      "        46 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.55m\n",
      "        47 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.43m\n",
      "        48 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.31m\n",
      "        49 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.19m\n",
      "        50 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            6.07m\n",
      "        51 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.94m\n",
      "        52 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.82m\n",
      "        53 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.70m\n",
      "        54 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.58m\n",
      "        55 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.46m\n",
      "        56 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.34m\n",
      "        57 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        58 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            5.10m\n",
      "        59 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.97m\n",
      "        60 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.85m\n",
      "        61 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.73m\n",
      "        62 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.61m\n",
      "        63 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.49m\n",
      "        64 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.37m\n",
      "        65 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.25m\n",
      "        66 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.12m\n",
      "        67 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            4.00m\n",
      "        68 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.88m\n",
      "        69 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.76m\n",
      "        70 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.64m\n",
      "        71 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.52m\n",
      "        72 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.40m\n",
      "        73 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.28m\n",
      "        74 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.15m\n",
      "        75 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            3.03m\n",
      "        76 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.91m\n",
      "        77 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.79m\n",
      "        78 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.67m\n",
      "        79 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.55m\n",
      "        80 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.43m\n",
      "        81 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.31m\n",
      "        82 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.18m\n",
      "        83 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            2.06m\n",
      "        84 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.94m\n",
      "        85 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.82m\n",
      "        86 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.70m\n",
      "        87 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.58m\n",
      "        88 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.46m\n",
      "        89 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.33m\n",
      "        90 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.21m\n",
      "        91 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            1.09m\n",
      "        92 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           58.22s\n",
      "        93 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           50.94s\n",
      "        94 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           43.65s\n",
      "        95 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           36.38s\n",
      "        96 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           29.10s\n",
      "        97 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           21.82s\n",
      "        98 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000           14.55s\n",
      "        99 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            7.27s\n",
      "       100 195923785634665546449869624710654194514209248812873904757767900848230842770539944000396265808857873033572436963932241920.0000            0.00s\n",
      "그래디언트 부스팅 트리 정확도: 0.7702582368655387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.79      0.70      0.74       105\n",
      "           2       0.62      0.65      0.63        20\n",
      "           3       0.88      0.91      0.89       813\n",
      "           4       0.78      0.84      0.81       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.83      0.71      0.77        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.59      0.63      0.61        38\n",
      "           9       0.86      0.76      0.81        25\n",
      "          10       0.86      0.80      0.83        30\n",
      "          11       0.64      0.67      0.66        83\n",
      "          12       0.35      0.54      0.42        13\n",
      "          13       0.52      0.38      0.44        37\n",
      "          14       0.08      0.50      0.13         2\n",
      "          15       0.38      0.33      0.35         9\n",
      "          16       0.71      0.74      0.72        99\n",
      "          17       0.56      0.42      0.48        12\n",
      "          18       0.61      0.55      0.58        20\n",
      "          19       0.73      0.66      0.69       133\n",
      "          20       0.71      0.50      0.59        70\n",
      "          21       0.67      0.59      0.63        27\n",
      "          22       0.33      0.14      0.20         7\n",
      "          23       0.58      0.58      0.58        12\n",
      "          24       0.47      0.47      0.47        19\n",
      "          25       0.86      0.61      0.72        31\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       0.33      0.50      0.40         4\n",
      "          28       0.43      0.30      0.35        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       0.40      0.33      0.36        12\n",
      "          31       0.62      0.38      0.48        13\n",
      "          32       0.89      0.80      0.84        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.50      0.43      0.46         7\n",
      "          35       0.25      0.17      0.20         6\n",
      "          36       0.80      0.73      0.76        11\n",
      "          37       0.29      1.00      0.44         2\n",
      "          38       0.33      0.33      0.33         3\n",
      "          39       0.67      0.40      0.50         5\n",
      "          40       0.67      0.40      0.50        10\n",
      "          41       0.50      0.50      0.50         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.67      0.67      0.67         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.20      1.00      0.33         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.60      0.58      0.57      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyride/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 정확도: 0.8165627782724845\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.78      0.75      0.77       105\n",
      "           2       0.68      0.75      0.71        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.68      0.68        38\n",
      "           9       0.81      0.88      0.85        25\n",
      "          10       0.90      0.87      0.88        30\n",
      "          11       0.68      0.72      0.70        83\n",
      "          12       0.46      0.46      0.46        13\n",
      "          13       0.68      0.62      0.65        37\n",
      "          14       0.17      1.00      0.29         2\n",
      "          15       0.57      0.44      0.50         9\n",
      "          16       0.72      0.77      0.75        99\n",
      "          17       0.73      0.67      0.70        12\n",
      "          18       0.86      0.60      0.71        20\n",
      "          19       0.71      0.71      0.71       133\n",
      "          20       0.70      0.50      0.58        70\n",
      "          21       0.66      0.78      0.71        27\n",
      "          22       0.33      0.14      0.20         7\n",
      "          23       0.64      0.75      0.69        12\n",
      "          24       0.62      0.53      0.57        19\n",
      "          25       0.92      0.71      0.80        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       0.67      0.50      0.57         4\n",
      "          28       0.43      0.30      0.35        10\n",
      "          29       0.50      0.75      0.60         4\n",
      "          30       0.67      0.50      0.57        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      0.90      0.95        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.67      0.57      0.62         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.73      0.73      0.73        11\n",
      "          37       0.25      0.50      0.33         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       1.00      0.40      0.57         5\n",
      "          40       0.67      0.40      0.50        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       0.80      0.80      0.80         5\n",
      "          45       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.70      0.65      0.65      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n",
      "15000 단어 사용 시 수행시간 : 0:25:08\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod_15k, cb_15k, lr_15k, lsvc_15k, tree_15k, forest_15k, grbt_15k, voting_classifier_15k = train_ml(tfidfv_15k, \n",
    "                                                                                                    y_train_15k, \n",
    "                                                                                                    tfidfv_test_15k, \n",
    "                                                                                                    y_test_15k)\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print('15000 단어 사용 시 수행시간 :', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "TozE_v2ozxMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6193232413178985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.79      0.39      0.52       105\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.75      0.92      0.82       813\n",
      "           4       0.46      0.96      0.62       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.04      0.08        25\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.76      0.37      0.50        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.74      0.28      0.41        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.67      0.67      0.67       133\n",
      "          20       0.00      0.00      0.00        70\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.00      0.00      0.00        19\n",
      "          25       0.00      0.00      0.00        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.11      0.08      0.08      2246\n",
      "weighted avg       0.52      0.62      0.53      2246\n",
      "\n",
      "CNB 정확도: 0.7671415850400712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.50      0.63        12\n",
      "           1       0.64      0.89      0.74       105\n",
      "           2       0.91      0.50      0.65        20\n",
      "           3       0.89      0.91      0.90       813\n",
      "           4       0.75      0.93      0.83       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.92      0.86      0.89        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.44      0.11      0.17        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.96      0.73      0.83        30\n",
      "          11       0.54      0.70      0.61        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.61      0.54      0.57        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.50      0.11      0.18         9\n",
      "          16       0.67      0.77      0.71        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.57      0.60      0.59        20\n",
      "          19       0.55      0.79      0.65       133\n",
      "          20       0.86      0.26      0.40        70\n",
      "          21       0.85      0.63      0.72        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.71      0.42      0.53        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.83      0.65      0.73        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.25      0.10      0.14        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       1.00      0.31      0.47        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       1.00      0.71      0.83         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       1.00      0.33      0.50         3\n",
      "          39       1.00      0.20      0.33         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       1.00      0.33      0.50         3\n",
      "          43       1.00      0.17      0.29         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.61      0.42      0.46      2246\n",
      "weighted avg       0.75      0.77      0.74      2246\n",
      "\n",
      "로지스틱 회귀 정확도: 0.8098842386464826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.73      0.78      0.76       105\n",
      "           2       0.70      0.70      0.70        20\n",
      "           3       0.92      0.93      0.92       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.93      1.00      0.97        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.71      0.69        38\n",
      "           9       0.82      0.92      0.87        25\n",
      "          10       0.93      0.87      0.90        30\n",
      "          11       0.65      0.73      0.69        83\n",
      "          12       0.57      0.31      0.40        13\n",
      "          13       0.57      0.62      0.60        37\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       0.67      0.44      0.53         9\n",
      "          16       0.71      0.76      0.74        99\n",
      "          17       0.80      0.67      0.73        12\n",
      "          18       0.81      0.65      0.72        20\n",
      "          19       0.67      0.69      0.68       133\n",
      "          20       0.60      0.49      0.54        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.69      0.75      0.72        12\n",
      "          24       0.59      0.53      0.56        19\n",
      "          25       0.92      0.74      0.82        31\n",
      "          26       1.00      0.88      0.93         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.50      0.30      0.37        10\n",
      "          29       0.57      1.00      0.73         4\n",
      "          30       1.00      0.58      0.74        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.80      0.80      0.80         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.33      0.27      0.30        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.50      0.40      0.44         5\n",
      "          40       0.67      0.20      0.31        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      1.00      1.00         3\n",
      "          43       0.86      1.00      0.92         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.72      0.63      0.66      2246\n",
      "weighted avg       0.81      0.81      0.80      2246\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 정확도: 0.7292965271593945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.67      0.59        12\n",
      "           1       0.61      0.64      0.63       105\n",
      "           2       0.56      0.50      0.53        20\n",
      "           3       0.91      0.90      0.90       813\n",
      "           4       0.79      0.82      0.80       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.69      0.64      0.67        14\n",
      "           7       0.17      0.33      0.22         3\n",
      "           8       0.62      0.63      0.62        38\n",
      "           9       0.77      0.80      0.78        25\n",
      "          10       0.67      0.53      0.59        30\n",
      "          11       0.59      0.65      0.62        83\n",
      "          12       0.21      0.23      0.22        13\n",
      "          13       0.45      0.54      0.49        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.14      0.11      0.12         9\n",
      "          16       0.60      0.64      0.62        99\n",
      "          17       0.60      0.25      0.35        12\n",
      "          18       0.53      0.50      0.51        20\n",
      "          19       0.54      0.58      0.56       133\n",
      "          20       0.54      0.43      0.48        70\n",
      "          21       0.47      0.59      0.52        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.45      0.42      0.43        12\n",
      "          24       0.33      0.37      0.35        19\n",
      "          25       0.73      0.52      0.60        31\n",
      "          26       1.00      0.50      0.67         8\n",
      "          27       1.00      0.25      0.40         4\n",
      "          28       0.33      0.30      0.32        10\n",
      "          29       0.22      0.50      0.31         4\n",
      "          30       0.56      0.42      0.48        12\n",
      "          31       0.80      0.31      0.44        13\n",
      "          32       0.67      0.60      0.63        10\n",
      "          33       0.67      0.80      0.73         5\n",
      "          34       0.50      0.43      0.46         7\n",
      "          35       0.50      0.17      0.25         6\n",
      "          36       0.28      0.45      0.34        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       0.17      0.20      0.18         5\n",
      "          40       1.00      0.30      0.46        10\n",
      "          41       0.44      0.50      0.47         8\n",
      "          42       0.25      0.33      0.29         3\n",
      "          43       0.38      0.50      0.43         6\n",
      "          44       0.67      0.80      0.73         5\n",
      "          45       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.73      2246\n",
      "   macro avg       0.51      0.47      0.46      2246\n",
      "weighted avg       0.73      0.73      0.73      2246\n",
      "\n",
      "결정 트리 정확도: 0.6211041852181657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.72      0.39      0.51       105\n",
      "           2       0.50      0.55      0.52        20\n",
      "           3       0.93      0.85      0.88       813\n",
      "           4       0.40      0.89      0.55       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.75      0.21      0.33        14\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00        38\n",
      "           9       1.00      0.16      0.28        25\n",
      "          10       0.89      0.80      0.84        30\n",
      "          11       0.61      0.61      0.61        83\n",
      "          12       0.00      0.00      0.00        13\n",
      "          13       0.00      0.00      0.00        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.62      0.83      0.71        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.65      0.38      0.48       133\n",
      "          20       0.57      0.11      0.19        70\n",
      "          21       0.50      0.04      0.07        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.00      0.00      0.00        12\n",
      "          24       0.50      0.11      0.17        19\n",
      "          25       0.67      0.06      0.12        31\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.50      0.10      0.17        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       1.00      0.80      0.89         5\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.15      0.16      2246\n",
      "weighted avg       0.62      0.62      0.58      2246\n",
      "\n",
      "랜덤 포레스트 정확도: 0.6714158504007124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.33      0.23        12\n",
      "           1       0.40      0.70      0.51       105\n",
      "           2       0.19      0.20      0.20        20\n",
      "           3       0.83      0.91      0.87       813\n",
      "           4       0.65      0.86      0.74       474\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       1.00      0.29      0.44        14\n",
      "           7       0.33      0.33      0.33         3\n",
      "           8       0.48      0.42      0.45        38\n",
      "           9       0.54      0.28      0.37        25\n",
      "          10       0.53      0.27      0.36        30\n",
      "          11       0.49      0.57      0.53        83\n",
      "          12       0.50      0.15      0.24        13\n",
      "          13       0.43      0.27      0.33        37\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.56      0.45      0.50        99\n",
      "          17       0.00      0.00      0.00        12\n",
      "          18       0.57      0.40      0.47        20\n",
      "          19       0.59      0.52      0.55       133\n",
      "          20       0.53      0.30      0.38        70\n",
      "          21       0.89      0.30      0.44        27\n",
      "          22       0.00      0.00      0.00         7\n",
      "          23       0.33      0.08      0.13        12\n",
      "          24       0.40      0.11      0.17        19\n",
      "          25       1.00      0.39      0.56        31\n",
      "          26       1.00      0.12      0.22         8\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00        10\n",
      "          29       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00        13\n",
      "          32       1.00      0.10      0.18        10\n",
      "          33       1.00      0.40      0.57         5\n",
      "          34       0.50      0.14      0.22         7\n",
      "          35       1.00      0.17      0.29         6\n",
      "          36       0.20      0.09      0.13        11\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         3\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       1.00      0.20      0.33        10\n",
      "          41       0.00      0.00      0.00         8\n",
      "          42       0.00      0.00      0.00         3\n",
      "          43       1.00      0.67      0.80         6\n",
      "          44       1.00      0.80      0.89         5\n",
      "          45       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.44      0.26      0.29      2246\n",
      "weighted avg       0.65      0.67      0.64      2246\n",
      "\n",
      "      Iter       Train Loss   Remaining Time \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1           1.4325           11.94m\n",
      "         2       95425.3579           11.91m\n",
      "         3      105570.6041           11.84m\n",
      "         4 593224062708261760.0000           11.71m\n",
      "         5 3774435173865725234928276254753926961504996704196152337310417818266040513071397885183910310310561420723401279705159106767064399872.0000           11.61m\n",
      "         6 3774435173865725234928276254753926961504996704196152337310417818266040513071397885183910310310561420723401279705159106767064399872.0000           11.49m\n",
      "         7 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           11.39m\n",
      "         8 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           11.32m\n",
      "         9 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           11.28m\n",
      "        10 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           11.17m\n",
      "        11 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           11.04m\n",
      "        12 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.92m\n",
      "        13 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.79m\n",
      "        14 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.66m\n",
      "        15 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.54m\n",
      "        16 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.42m\n",
      "        17 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.30m\n",
      "        18 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.17m\n",
      "        19 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           10.04m\n",
      "        20 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.91m\n",
      "        21 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.79m\n",
      "        22 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.66m\n",
      "        23 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.53m\n",
      "        24 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.41m\n",
      "        25 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.28m\n",
      "        26 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.16m\n",
      "        27 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            9.03m\n",
      "        28 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.90m\n",
      "        29 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.78m\n",
      "        30 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.66m\n",
      "        31 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.53m\n",
      "        32 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.40m\n",
      "        33 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.28m\n",
      "        34 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.15m\n",
      "        35 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            8.03m\n",
      "        36 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.91m\n",
      "        37 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.78m\n",
      "        38 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.66m\n",
      "        39 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.54m\n",
      "        40 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.41m\n",
      "        41 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.29m\n",
      "        42 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.16m\n",
      "        43 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.04m\n",
      "        44 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.91m\n",
      "        45 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.79m\n",
      "        46 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.67m\n",
      "        47 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.54m\n",
      "        48 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.42m\n",
      "        49 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.30m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        50 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.17m\n",
      "        51 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            6.05m\n",
      "        52 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.92m\n",
      "        53 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.80m\n",
      "        54 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.68m\n",
      "        55 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.55m\n",
      "        56 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.43m\n",
      "        57 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.31m\n",
      "        58 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.18m\n",
      "        59 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            5.06m\n",
      "        60 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.93m\n",
      "        61 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.81m\n",
      "        62 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.69m\n",
      "        63 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.57m\n",
      "        64 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.44m\n",
      "        65 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.32m\n",
      "        66 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.20m\n",
      "        67 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            4.07m\n",
      "        68 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.95m\n",
      "        69 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.82m\n",
      "        70 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.70m\n",
      "        71 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.58m\n",
      "        72 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.45m\n",
      "        73 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.33m\n",
      "        74 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.21m\n",
      "        75 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            3.08m\n",
      "        76 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.96m\n",
      "        77 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.84m\n",
      "        78 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.71m\n",
      "        79 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.59m\n",
      "        80 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.47m\n",
      "        81 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.34m\n",
      "        82 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.22m\n",
      "        83 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            2.10m\n",
      "        84 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.97m\n",
      "        85 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.85m\n",
      "        86 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.73m\n",
      "        87 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.60m\n",
      "        88 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.48m\n",
      "        89 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.36m\n",
      "        90 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.23m\n",
      "        91 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            1.11m\n",
      "        92 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           59.21s\n",
      "        93 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           51.81s\n",
      "        94 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           44.40s\n",
      "        95 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           37.00s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        96 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           29.59s\n",
      "        97 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           22.20s\n",
      "        98 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000           14.80s\n",
      "        99 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            7.40s\n",
      "       100 1489548745818530758244232012042654711502171239857813292906777294351633452202689035463067802524827847410009904379930627599745172362994401857765376.0000            0.00s\n",
      "그래디언트 부스팅 트리 정확도: 0.769813000890472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.76      0.69      0.72       105\n",
      "           2       0.60      0.75      0.67        20\n",
      "           3       0.87      0.91      0.89       813\n",
      "           4       0.77      0.84      0.81       474\n",
      "           5       0.50      0.20      0.29         5\n",
      "           6       0.91      0.71      0.80        14\n",
      "           7       0.25      0.33      0.29         3\n",
      "           8       0.60      0.63      0.62        38\n",
      "           9       0.90      0.76      0.83        25\n",
      "          10       0.80      0.80      0.80        30\n",
      "          11       0.62      0.67      0.65        83\n",
      "          12       0.50      0.46      0.48        13\n",
      "          13       0.54      0.35      0.43        37\n",
      "          14       0.14      0.50      0.22         2\n",
      "          15       0.33      0.33      0.33         9\n",
      "          16       0.71      0.71      0.71        99\n",
      "          17       0.56      0.42      0.48        12\n",
      "          18       0.71      0.50      0.59        20\n",
      "          19       0.73      0.68      0.70       133\n",
      "          20       0.69      0.44      0.54        70\n",
      "          21       0.68      0.63      0.65        27\n",
      "          22       0.33      0.14      0.20         7\n",
      "          23       0.67      0.67      0.67        12\n",
      "          24       0.60      0.47      0.53        19\n",
      "          25       0.81      0.68      0.74        31\n",
      "          26       0.75      0.75      0.75         8\n",
      "          27       1.00      0.50      0.67         4\n",
      "          28       0.33      0.20      0.25        10\n",
      "          29       0.33      0.75      0.46         4\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.60      0.46      0.52        13\n",
      "          32       1.00      0.80      0.89        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       0.75      0.43      0.55         7\n",
      "          35       0.33      0.17      0.22         6\n",
      "          36       0.50      0.55      0.52        11\n",
      "          37       0.50      1.00      0.67         2\n",
      "          38       0.33      0.33      0.33         3\n",
      "          39       0.67      0.40      0.50         5\n",
      "          40       1.00      0.40      0.57        10\n",
      "          41       0.50      0.62      0.56         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.60      0.50      0.55         6\n",
      "          44       0.57      0.80      0.67         5\n",
      "          45       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.62      0.58      0.58      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sallyride/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보팅 정확도: 0.8178984861976848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.80      0.75      0.77       105\n",
      "           2       0.70      0.80      0.74        20\n",
      "           3       0.92      0.94      0.93       813\n",
      "           4       0.82      0.88      0.85       474\n",
      "           5       1.00      0.20      0.33         5\n",
      "           6       0.93      0.93      0.93        14\n",
      "           7       1.00      0.67      0.80         3\n",
      "           8       0.68      0.71      0.69        38\n",
      "           9       0.80      0.80      0.80        25\n",
      "          10       0.90      0.90      0.90        30\n",
      "          11       0.69      0.71      0.70        83\n",
      "          12       0.67      0.46      0.55        13\n",
      "          13       0.63      0.65      0.64        37\n",
      "          14       0.25      1.00      0.40         2\n",
      "          15       0.57      0.44      0.50         9\n",
      "          16       0.75      0.76      0.75        99\n",
      "          17       0.73      0.67      0.70        12\n",
      "          18       0.79      0.55      0.65        20\n",
      "          19       0.71      0.71      0.71       133\n",
      "          20       0.65      0.49      0.56        70\n",
      "          21       0.63      0.81      0.71        27\n",
      "          22       0.50      0.14      0.22         7\n",
      "          23       0.64      0.75      0.69        12\n",
      "          24       0.67      0.63      0.65        19\n",
      "          25       0.88      0.74      0.81        31\n",
      "          26       0.88      0.88      0.88         8\n",
      "          27       1.00      0.50      0.67         4\n",
      "          28       0.43      0.30      0.35        10\n",
      "          29       0.44      1.00      0.62         4\n",
      "          30       0.60      0.50      0.55        12\n",
      "          31       0.75      0.46      0.57        13\n",
      "          32       1.00      0.90      0.95        10\n",
      "          33       0.71      1.00      0.83         5\n",
      "          34       0.80      0.57      0.67         7\n",
      "          35       1.00      0.33      0.50         6\n",
      "          36       0.58      0.64      0.61        11\n",
      "          37       0.50      0.50      0.50         2\n",
      "          38       0.50      0.33      0.40         3\n",
      "          39       1.00      0.40      0.57         5\n",
      "          40       1.00      0.40      0.57        10\n",
      "          41       0.80      0.50      0.62         8\n",
      "          42       1.00      0.67      0.80         3\n",
      "          43       0.83      0.83      0.83         6\n",
      "          44       0.57      0.80      0.67         5\n",
      "          45       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.74      0.66      0.66      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n",
      "20000 단어 사용 시 수행시간 : 0:25:33\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod_20k, cb_20k, lr_20k, lsvc_20k, tree_20k, forest_20k, grbt_20k, voting_classifier_20k = train_ml(tfidfv_20k, \n",
    "                                                                                                    y_train_20k, \n",
    "                                                                                                    tfidfv_test_20k, \n",
    "                                                                                                    y_test_20k)\n",
    "sec = time.time()-start\n",
    "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
    "times = times[0]\n",
    "print('20000 단어 사용 시 수행시간 :', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "l4ZOxqsz0R_H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 네 번쨰 샘플의 원문\n",
      "모든 단어 사용 시 해당 샘플의 레이블\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 네 번쨰 샘플의 원문\")\n",
    "x_test_n[3]\n",
    "print(\"모든 단어 사용 시 해당 샘플의 레이블\")\n",
    "y_test_n[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8746KAWY1DbR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 단어 사용 시 네 번쨰 샘플의 원문\n",
      "5000 단어 사용 시 해당 샘플의 레이블\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"5000 단어 사용 시 네 번쨰 샘플의 원문\")\n",
    "x_test_5k[3]\n",
    "print(\"5000 단어 사용 시 해당 샘플의 레이블\")\n",
    "y_test_5k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "5v9ffP5k1DSq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 단어 사용 시 네 번쨰 샘플의 원문\n",
      "15000 단어 사용 시 해당 샘플의 레이블\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"15000 단어 사용 시 네 번쨰 샘플의 원문\")\n",
    "x_test_15k[3]\n",
    "print(\"15000 단어 사용 시 해당 샘플의 레이블\")\n",
    "y_test_15k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "55YXp8n81C-x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 단어 사용 시 네 번쨰 샘플의 원문\n",
      "20000 단어 사용 시 해당 샘플의 레이블\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"20000 단어 사용 시 네 번쨰 샘플의 원문\")\n",
    "x_test_20k[3]\n",
    "print(\"20000 단어 사용 시 해당 샘플의 레이블\")\n",
    "y_test_20k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "oYvvw4T82U6W"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 26506 features, but MultinomialNB is expecting 9670 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m probability_n \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidfv_test_n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m probability_5k \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mpredict_proba(tfidfv_test_5k[\u001b[38;5;241m3\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m probability_15k \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mpredict_proba(tfidfv_test_15k[\u001b[38;5;241m3\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:125\u001b[0m, in \u001b[0;36m_BaseNB.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Return probability estimates for the test vector X.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        order, as they appear in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_log_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:103\u001b[0m, in \u001b[0;36m_BaseNB.predict_log_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03mReturn log-probability estimates for the test vector X.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    order, as they appear in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# normalize by P(x) = P(f_1, ..., f_n)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:519\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 26506 features, but MultinomialNB is expecting 9670 features as input."
     ]
    }
   ],
   "source": [
    "probability_n = mod.predict_proba(tfidfv_test_n[3])[0]\n",
    "probability_5k = mod.predict_proba(tfidfv_test_5k[3])[0]\n",
    "probability_15k = mod.predict_proba(tfidfv_test_15k[3])[0]\n",
    "probability_20k = mod.predict_proba(tfidfv_test_20k[3])[0]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('all words')\n",
    "plt.bar(mod.classes_, probability_n)\n",
    "plt.xticks(mod.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('5000 words')\n",
    "plt.bar(mod.classes_, probability_5k)\n",
    "plt.xticks(mod.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('15000 words')\n",
    "plt.bar(mod.classes_, probability_15k)\n",
    "plt.xticks(mod.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('20000 words')\n",
    "plt.bar(mod.classes_, probability_20k)\n",
    "plt.xticks(mod.classes_)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "bzJ5cqTP4zlb"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 26506 features, but MultinomialNB is expecting 9670 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모든 단어 사용 시 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidfv_test_n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5000 단어 사용 시 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, mod\u001b[38;5;241m.\u001b[39mpredict(tfidfv_test_5k[\u001b[38;5;241m3\u001b[39m]))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m15000 단어 사용 시 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, mod\u001b[38;5;241m.\u001b[39mpredict(tfidfv_test_15k[\u001b[38;5;241m3\u001b[39m]))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:82\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:519\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 26506 features, but MultinomialNB is expecting 9670 features as input."
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 : \", mod.predict(tfidfv_test_n[3]))\n",
    "print(\"5000 단어 사용 시 : \", mod.predict(tfidfv_test_5k[3]))\n",
    "print(\"15000 단어 사용 시 : \", mod.predict(tfidfv_test_15k[3]))\n",
    "print(\"20000 단어 사용 시 : \", mod.predict(tfidfv_test_20k[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "4z_bBKkq5SU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 단어 사용 시 혼동 행렬\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 26506 features, but MultinomialNB is expecting 9670 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모든 단어 사용 시 혼동 행렬\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgraph_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfidfv_test_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5000 단어 사용 시 혼동 행렬\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m graph_confusion_matrix(mod, tfidfv_test_5k, y_test_5k)\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mgraph_confusion_matrix\u001b[0;34m(mod, x_test, y_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgraph_confusion_matrix\u001b[39m(mod, x_test, y_test):\u001b[38;5;66;03m#, classes_name):\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m   df_cm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(confusion_matrix(y_test, \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;66;03m#, index=classes_name, columns=classes_name)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:82\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    Predicted target values for X.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_joint_log_likelihood(X)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:519\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 26506 features, but MultinomialNB is expecting 9670 features as input."
     ]
    }
   ],
   "source": [
    "print(\"모든 단어 사용 시 혼동 행렬\")\n",
    "graph_confusion_matrix(mod, tfidfv_test_n, y_test_n)\n",
    "print(\"5000 단어 사용 시 혼동 행렬\")\n",
    "graph_confusion_matrix(mod, tfidfv_test_5k, y_test_5k)\n",
    "print(\"15000 단어 사용 시 혼동 행렬\")\n",
    "graph_confusion_matrix(mod, tfidfv_test_15k, y_test_15k)\n",
    "print(\"20000 단어 사용 시 혼동 행렬\")\n",
    "graph_confusion_matrix(mod, tfidfv_test_20k, y_test_20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDEL4F3NSMen"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[GoingDeeperNLP_4] NewsCategory",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
